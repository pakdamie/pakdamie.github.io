[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Damie Pak, PhD",
    "section": "",
    "text": "Hello, I am Damie (Dah-mie) Pak. I am a general all-purpose quantitative/theoretical ecologist with an interest in insect pests and infectious disease. I received my doctorate at The Pennsylvania State University with Dr. Ottar Bjornstad. I then did a short six-month postdoc with Dr. Kat Shea before moving to Cornell to work with Dr. Megan Greischar. I am now a postdoctoral fellow at the University of South Carolina with Tad Dallas.\nMy main tools of the trade involve using mathematical models and data analysis! With each project, I try to learn a new analytical tool (wavelet analysis, phylogenetic regression, network analysis, etc.) to add to my toolbox. My main passion is insects because my first love was identifying parasitoid wasps. My doctoral work focused on agricultural pests. However, I also have a keen interest in disease ecology. I believe the most interesting questions in ecology lie at the intersection of theory and application. Check out the research tab to see more of my work!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "CV",
    "section": "",
    "text": "Copyright 2024, Damie Pak"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog posts",
    "section": "",
    "text": "Interesting things I learned this week (August 19th)\n\n\n\nList\n\n\n\nWhen coding is slow… Cry!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn agent based model of within-host malaria\n\n\n\nMaterial\n\n\n\nA short introduction to doing an agent-based malaria model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStochastic SIS model\n\n\n\nTutorial\n\n\n\nA short tutorial on how to model stochastic SIS model on a network.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteresting stuff I read (August 12)\n\n\n\nReading\n\n\n\nIf I can turn back time, I’ll probably do a lot easier statistics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt’s weird we don’t talk about Malthus\n\n\n\nEssay\n\n\n\nMalthus is associated with exponential growth… and bad famine policies that led to the death of millions. Why don’t we ever talk about it in Intro to Ecology classes?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinite versus instantaneous rate\n\n\n\nTutorial\n\n\n\nFinite and instanteous rates can be confusing especially when we talk about mortality rates.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGRFP Statements\n\n\n\nMaterial\n\n\n\n\n\n\n\nDamie Pak\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating ecology models: A series of tutorial (Part 2)\n\n\n\nCode\n\n\nTutorial\n\n\n\nHow to use Euler method to solve differential equation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson process\n\n\n\nTutorial\n\n\n\nA short tutorial on understanding the poisson process\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuest lecture slides for teaching the Lotka-Volterra Predator/Prey dynamics\n\n\n\nSlides\n\n\nMaterial\n\n\n\nGuest lecture slides for teaching\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteresting stuff I read (September 3rd)\n\n\n\nReading\n\n\n\nOne paper is still a paper!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteresting stuff I read (August 19th)\n\n\n\nReading\n\n\n\nThermal performance curves are radical!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteresting things I learned this week (August 26th)\n\n\n\nList\n\n\n\nStochasticity in models - why not!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating a scale-free network\n\n\n\nCode\n\n\nTutorial\n\n\n\nOne possible (possibly bad) way of modeling a spatial network that is also scale-free\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExponential waiting time\n\n\n\nTutorial\n\n\n\nWhy do we assume that the waiting time in a compartmental model is exponentially distributed?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating ecology models: A series of tutorial\n\n\n\nCode\n\n\nTutorial\n\n\n\nHow to model a single-species population the first time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA proof of concept: a coin-toss game\n\n\n\nCode\n\n\n\nWhat I thought was a clever analogy of insects at hotter temperatures\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating spatial network (Part 2)\n\n\n\nTutorial\n\n\nCode\n\n\n\nHow to simulate a semi-realistic spatial network, maybe in kind of a hackey way\n\n\n\nDamie Pak\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbouheif Mean C\n\n\n\nMaterial\n\n\n\nAbouheif Mean C is one way to check if there is a phylogenetic signal: how does it work?\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "In the particular is contained the universal. - James Joyce\nBelow are some projects I have pursued:"
  },
  {
    "objectID": "research.html#side-by-side-layout",
    "href": "research.html#side-by-side-layout",
    "title": "Research",
    "section": "",
    "text": "Here is some text that you want to place next to a figure. You can write any content here."
  },
  {
    "objectID": "research.html#temperature-and-insect-outbreak",
    "href": "research.html#temperature-and-insect-outbreak",
    "title": "Research",
    "section": "Temperature and insect outbreak",
    "text": "Temperature and insect outbreak\n\n\n\n\n\n\nFor my doctoral work with Dr. Ottar Bjornstad at Penn State, I worked on understanding the dynamics of insect outbreaks. Specifically, I am interested in the role of climate on driving the phenology of tortricid moth pests. The spring emergence of the adult stages, for example, is influenced both by local temperatures and large scale-climate oscillations such as the North Atlantic Oscillation and the Arctic Oscillation and Arctic Oscillation (Local and Regional Climate Variables Driving Spring Phenology of Tortricid Pests: A 36-Year Study). Each tortricid species, because of their unique life-histories, are sensitive to these cues at different temporal windows. For example, species with multiple generations"
  },
  {
    "objectID": "research.html#tick-community",
    "href": "research.html#tick-community",
    "title": "Research",
    "section": "Tick community",
    "text": "Tick community\n\n\n\n\n\nFor my doctoral work with Dr. Ottar Bjornstad, I"
  },
  {
    "objectID": "research.html#the-vector-community-community",
    "href": "research.html#the-vector-community-community",
    "title": "Research",
    "section": "The vector community community",
    "text": "The vector community community\n\n\n\n\n\nFor my doctoral work with Dr. Ottar Bjornstad, I\n\n\n\n\n\n\n\n\nFor my doctoral work with Dr. Ottar Bjornstad, I"
  },
  {
    "objectID": "research.html#a-community-perspective-of-vectors",
    "href": "research.html#a-community-perspective-of-vectors",
    "title": "Research",
    "section": "A community perspective of vectors",
    "text": "A community perspective of vectors\n\n\n\n\n\n\nI’m fascinated by communities of vector species! When investigating vector-borne diseases, we tend to focus on one species at a time, but there can be multiple vectors, each with its own unique ecology. In collaboration with Dr. Joyce Sakamoto, we analyzed a century’s worth of tick data (A 117-year retrospective analysis of Pennsylvania tick community dynamics). We showcased how the dominant vector species have changed over the century, as well as the spatial partitioning between vector species.\n\n\n\n\n\n\n\n\nCurrently with my postdoctoral work with Tad Dallas, a project I’m working on is how disturbance can structure the relative abundance of different vectors."
  },
  {
    "objectID": "research.html#trees-trees-trees",
    "href": "research.html#trees-trees-trees",
    "title": "Research",
    "section": "Trees, trees, trees",
    "text": "Trees, trees, trees\n\n\n\n\n\nFor my doctoral work with Dr. Ottar Bjornstad, I"
  },
  {
    "objectID": "research.html#ecological-management",
    "href": "research.html#ecological-management",
    "title": "Research",
    "section": "Ecological management",
    "text": "Ecological management\n\n\n\n\n\n\nFor my short six-month postdoc with Dr. Katriona Shea (because moving doing COVID times is difficult), I learned about decision theory and how to apply it for vaccine allocation. Specifically, under significant uncertainty- what is the best course of action? Is there always going to be an optimal choice?"
  },
  {
    "objectID": "research.html#within-host-modelig",
    "href": "research.html#within-host-modelig",
    "title": "Research",
    "section": "Within-host modelig",
    "text": "Within-host modelig\n\n\n\n\n\nFor my doctoral work with Dr. Ottar Bjornstad, I"
  },
  {
    "objectID": "research.html#ecological-management-1",
    "href": "research.html#ecological-management-1",
    "title": "Research",
    "section": "Ecological management",
    "text": "Ecological management"
  },
  {
    "objectID": "posts/helloworld.html",
    "href": "posts/helloworld.html",
    "title": "Damie Pak",
    "section": "",
    "text": "Hello this is a blog post"
  },
  {
    "objectID": "research.html#reproductive-phenology",
    "href": "research.html#reproductive-phenology",
    "title": "Research",
    "section": "Reproductive phenology",
    "text": "Reproductive phenology\n\n\n\n\n\n\nCollaborating with Dr. Jesse Lasky, I was interested in looking at phenology in another system (Multiscale phenological niches of seed fall in diverse Amazonian plant communities)."
  },
  {
    "objectID": "research.html#tortricid-moth-pests",
    "href": "research.html#tortricid-moth-pests",
    "title": "Research",
    "section": "Tortricid moth pests",
    "text": "Tortricid moth pests\n\n\n\n\n\n\nFor my doctoral work with Dr. Ottar Bjornstad at Penn State, I worked on understanding the dynamics of insect outbreaks. Specifically, I am interested in the role of climate on driving the phenology of tortricid moth pests. The spring emergence of the adult stages, for example, is influenced both by local temperatures and large scale-climate oscillations such as the North Atlantic Oscillation and the Arctic Oscillation (Local and Regional Climate Variables Driving Spring Phenology of Tortricid Pests: A 36-Year Study). Each tortricid species, because of their unique life-histories, are sensitive to these cues at different temporal windows. Additionally, I also use mathematical modeling to understand how diapause, a state of suspended development, can be incorporated for long-term forecasting (Incorporating Diapause to Predict the Interannual Dynamics of an Important Agricultural Pest)"
  },
  {
    "objectID": "research.html#reproductive-phenology-of-neotropical-trees",
    "href": "research.html#reproductive-phenology-of-neotropical-trees",
    "title": "Research",
    "section": "Reproductive phenology of neotropical trees",
    "text": "Reproductive phenology of neotropical trees\n\n\n\n\n\n\nIn my collaboration with Dr. Jesse Lasky (Multiscale phenological niches of seed fall in diverse Amazonian plant communities), we applied wavelet analysis to long-term time series data from two hyperdiverse plant communities in Peru and Ecuador. We analyzed the temporal patterns of synchrony and compensatory dynamics in seed dispersal. Our findings show that there is community-wide reproductive synchrony due to shared environmental responses and positive interactions. Additionally, there is evidence of temporal niche partitioning!"
  },
  {
    "objectID": "research.html#within-host-modeling",
    "href": "research.html#within-host-modeling",
    "title": "Research",
    "section": "Within-host modeling",
    "text": "Within-host modeling\n\n\n\n\n\nFor my doctoral work with Dr. Ottar Bjornstad, I"
  },
  {
    "objectID": "research.html#climate-and-tortricid-moth-pests",
    "href": "research.html#climate-and-tortricid-moth-pests",
    "title": "Research",
    "section": "Climate and tortricid moth pests",
    "text": "Climate and tortricid moth pests\n\n\n\n\n\n\nFor my doctoral work with Dr. Ottar Bjornstad, I investigated how the environment (local temperature) influences the phenology of insect pests. For example, by using a mathematical model, I demonstrated how temperature can predict the phenology of the codling moth (Incorporating Diapause to Predict the Interannual Dynamics of an Important Agricultural Pest). Additionally, by analyzing the time series of five pest species in Pennsylvania, I showed how their phenology is driven by two large scale-climate oscillations: the North Atlantic Oscillation and the Arctic Oscillation (Local and Regional Climate Variables Driving Spring Phenology of Tortricid Pests: A 36-Year Study)."
  },
  {
    "objectID": "research.html#within-host-modeling-of-malaria",
    "href": "research.html#within-host-modeling-of-malaria",
    "title": "Research",
    "section": "Within-host modeling of malaria",
    "text": "Within-host modeling of malaria\n\n\n\n\n\n\nIn my postdoctoral work with Dr. Megan Greischar, I investigated an understudied trait: the burst size of malaria parasites. The burst size determines the number of daughter cells that emerge from each infected RBC. Because a larger burst size allows the parasite to proliferate faster, an interesting question arises: why is it not higher? (Proliferation in malaria parasites: how resource limitation can prevent the evolution of greater virulence). I am also finishing a manuscript that investigates the role of burst size across all parasite species."
  },
  {
    "objectID": "posts/coin_flipping/coin_flip.html",
    "href": "posts/coin_flipping/coin_flip.html",
    "title": "A proof of concept: a coin-toss game",
    "section": "",
    "text": "This is a proof-of-concept for a research project I’m developing. Therefore, this is written more for me than for a general audience (sorry!). I can’t give it all away now, but hopefully it’s a taste of what I’m doing. Instead of an ecological question, let’s imagine you are hosting a BBQ and you somehow got a large group of your friends to play a lawn game. Everyone is given a coin and told to flip. If you get heads, you proceed one step. If you get tails, you die (specifically, you just lay down and stay in place). You ‘win’ if you can make it 10 paces away. Here is a schematic below:\n\nBut let’s make it more interesting! Let’s assume that the coin can be super biased. Instead of a 50% chance of dying, I manipulate it so that the chance of getting tails can vary from 1% to 100%. Also let’s assume that I introduce some variability. Some friends can only take very small steps and other friends can take larger steps. They somehow need to cumulatively take 10 paces to win, but you can see that there are advantages to those who can take very large steps.\nMy question is what does it look like at the end of the finish line. Specifically, what are the group of individuals that are able to finish (i.e do they take small steps or big steps?) and what is the timing? How does this differ depending on what kind of mortality coin I give them and what kind of steps I allow them to take?"
  },
  {
    "objectID": "posts/coin_flipping/coin_flip.html#a-more-realistic-math-ier-one",
    "href": "posts/coin_flipping/coin_flip.html#a-more-realistic-math-ier-one",
    "title": "A proof of concept: coin-toss game",
    "section": "A more realistic math-ier one",
    "text": "A more realistic math-ier one"
  },
  {
    "objectID": "posts/coin_flipping/coin_flip.html#putting-it-all-together",
    "href": "posts/coin_flipping/coin_flip.html#putting-it-all-together",
    "title": "A proof of concept: coin-toss game",
    "section": "Putting it all together",
    "text": "Putting it all together\n\ndeath_function &lt;- function(size, mort_prob){\n  sampled &lt;- sample(c(0,1), size,replace = TRUE, prob =c(mort_prob, 1- mort_prop))\n  return(sampled)\n}\n\n\ndevelopment_function &lt;- function(size, prob, id){\n  \n  if(id ==1){\n  sampled &lt;- runif(seq(0,1), size, replace = TRUE,)\n  }\n  else if (id ==2){\n  sampled &lt;- runif(seq(1,2), size, replace = TRUE,)\n  }\n  else if (id ==3){\n  sampled &lt;- runif(seq(2,3), size, replace = TRUE,)\n  }\n  return(sampled)\n}"
  },
  {
    "objectID": "posts/coin_flipping/coin_flip.html#an-introduction",
    "href": "posts/coin_flipping/coin_flip.html#an-introduction",
    "title": "A proof of concept: a coin-toss game",
    "section": "",
    "text": "This is a proof-of-concept for a research project I’m developing. Therefore, this is written more for me than for a general audience (sorry!). I can’t give it all away now, but hopefully it’s a taste of what I’m doing. Instead of an ecological question, let’s imagine you are hosting a BBQ and you somehow got a large group of your friends to play a lawn game. Everyone is given a coin and told to flip. If you get heads, you proceed one step. If you get tails, you die (specifically, you just lay down and stay in place). You ‘win’ if you can make it 10 paces away. Here is a schematic below:\n\nBut let’s make it more interesting! Let’s assume that the coin can be super biased. Instead of a 50% chance of dying, I manipulate it so that the chance of getting tails can vary from 1% to 100%. Also let’s assume that I introduce some variability. Some friends can only take very small steps and other friends can take larger steps. They somehow need to cumulatively take 10 paces to win, but you can see that there are advantages to those who can take very large steps.\nMy question is what does it look like at the end of the finish line. Specifically, what are the group of individuals that are able to finish (i.e do they take small steps or big steps?) and what is the timing? How does this differ depending on what kind of mortality coin I give them and what kind of steps I allow them to take?"
  },
  {
    "objectID": "posts/coin_flipping/coin_flip.html#the-simplest-code",
    "href": "posts/coin_flipping/coin_flip.html#the-simplest-code",
    "title": "A proof of concept: a coin-toss game",
    "section": "The simplest code",
    "text": "The simplest code\nFor the death function, I’m going to use sample until I think a bit more about the gritty mathematics. There is a binary outcome: you survived in this timestep or you perished in this timestep. But we can directly manipulate the probability of mortality.\n\ndeath_function &lt;- function(size, mort_prob){\n  sampled &lt;- sample(c(0,1), size,replace = TRUE, prob =c(mort_prob, 1- mort_prob))\n  return(sampled)\n}\n\nNow, how do our friends progress through the lawn game. We can give everyone a number (1,2,3) and depending on your number, you can take large steps or very small. You can see that if you are in Group 1, you take smaller steps than individuals in Group 3.\n\nprogress_function &lt;- function(id){\n  \n  if(id ==1){\n  sampled &lt;- runif(1,min =0, max =3)\n  }\n  else if (id ==2){\n  sampled &lt;- runif(1,min = 2,max=5)\n  }\n  else if (id ==3){\n  sampled &lt;- runif(1,min = 5, max =10)\n  }\n  return(sampled)\n}\n\nNow here is the most convoluted code of how the race can begin. A gist of it is that for anyone who has not died, I make them flip the coin. If it’s 0, they stay in place and I record at what time they ‘died’. If it’s a 1, they are still alive where they can make progress to winning. If they accumulate 10 steps, they won and wait while everyone finishes (by either ‘dying’ or ‘winning’).\n\n\nCode\nlawn_race_function &lt;- function(size, mort_prob, progress_time,time_step) {\n  full_df &lt;- data.frame(\n      current_time = rep(0, size),\n      time_event = rep(0, size),\n      status = rep(1, size),\n      progress = rep(0, size),\n       id = rep(c(1, 2, 3), length = size),\n       friend_number = seq(1, size))\n\n  survived_subsetted &lt;- full_df [full_df $status == 1 ,]\n  \n  i = 0\n  \n  while (nrow(full_df [full_df $status == 1 ,]) != 0) {\n    \n    i = i + 1\n    dead_developed_already_subsetted &lt;- full_df[full_df$status %in% c(0,2),]\n    survived_subsetted &lt;- full_df [full_df $status == 1 ,]\n    survived_individuals &lt;- nrow(survived_subsetted)\n ###If there are surviving individuals\n      \n      survived_subsetted$current_time &lt;- i\n\n      ### Did they die in this time-step?\n      survived_subsetted$status &lt;- death_function(survived_individuals, mort_prob)\n      \n      if(nrow(  survived_subsetted[survived_subsetted$status == 0, ])!=0){\n      \n      survived_subsetted[survived_subsetted$status == 0, ]$time_event &lt;- i\n\n      }\n      ### Progressed\n      growing_indviduals &lt;- survived_subsetted[survived_subsetted$status == 1, ]\n\n      ###If there are those that will grow\n      if(nrow(growing_indviduals) !=0){\n      \n      growing_indviduals$progress &lt;- round(growing_indviduals $progress + \n                                            time_step*sapply(X = growing_indviduals $id, FUN = progress_function ), 3)\n\n      developed &lt;- growing_indviduals[growing_indviduals$progress &gt;= progress_time, ]\n\n      ###If there are those developed \n      if(nrow(developed) != 0){\n      growing_indviduals[growing_indviduals$progress &gt;= progress_time, ]$status &lt;- 2\n      growing_indviduals[growing_indviduals$status == 2, ]$time_event &lt;- i\n      }\n      }\n      \n      full_df &lt;- rbind(dead_developed_already_subsetted ,\n        survived_subsetted[survived_subsetted$status == 0, ],\n       growing_indviduals\n      )\n  \n  \n  }\n  return(full_df)\n}"
  },
  {
    "objectID": "posts/coin_flipping/coin_flip.html#the-result",
    "href": "posts/coin_flipping/coin_flip.html#the-result",
    "title": "A proof of concept: a coin-toss game",
    "section": "The result",
    "text": "The result\nSo I set two matches with 100,000 of my friends. The first match, the probability of dying at each time step is 0.001 and you must make 10 steps to win. The second match, the probability of dying at each time step is 0.10 and still you must take 10 steps to win. What does it look like between the two races?\n\ndf_lawn_race1&lt;- lawn_race_function(1e5,0.01,10,time_step = 1/5)\ndf_lawn_race2&lt;- lawn_race_function(1e5,0.40,10,time_step = 1/5)\n\n\nfirst_panel / second_panel +   plot_layout(guides = 'collect')\n\n\n\n\n\n\n\n\nSo it may be intuitive, but I like having this simulation and figure. When you’re in a race where the chance of mortality is very small, all groups are able to effectively ‘win’. The slower group (Group 3 with the star symbol!) may take a lot longer but eventually they will reach the finish line. However, in the second situation (the bottom graph), with greater chance for mortality, the one who are able to finish the race faster (Group 1) are more likely to win. With each time step.\nLet’s take a new perspective\nSo everyone who won in the game, what does it look as a cumulative proportion over time. The first race (dark green) and second race (blue) are quite different!\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\nggplot(df_full, aes(x = time_event, y= prop, color = as.factor(facet), group = as.factor(facet)))+\n geom_line(size =1.2)+\n  xlab(\"Time\")+\n  ylab(\"Cumulative proportion winning\")+\n  scale_color_manual(name = \"Race\",values = c(`1` = 'darkgreen', `2` = 'blue'))+\n  theme_classic()+\n theme(axis.text = element_text(size = 14),\n        axis.title = element_text(size = 14))+xlim(0,60)\n\n\n\n\n\n\n\n\nHuh… Could there be more variability of individuals winning in the first race?"
  },
  {
    "objectID": "posts/interesting_paper_week/interestingpaper1.html",
    "href": "posts/interesting_paper_week/interestingpaper1.html",
    "title": "Interesting stuff I read (August 12)",
    "section": "",
    "text": "Here is stuff that I read around this week and last week. Most of the readings are related to science and my job (ew), but some are just related to more of my hobbies and interests."
  },
  {
    "objectID": "posts/interesting_paper_week/interestingpaper1.html#simplicity-and-complexity-in-ecological-data-analysis",
    "href": "posts/interesting_paper_week/interestingpaper1.html#simplicity-and-complexity-in-ecological-data-analysis",
    "title": "Interesting stuff I read (August 12)",
    "section": "Simplicity and complexity in ecological data analysis",
    "text": "Simplicity and complexity in ecological data analysis\nPaul A. Martaugh 2007\nI really liked this paper because it takes a lot of balls to go back to your old papers and criticize your own statistical analyses. The author explains what he did for his original statistics then shows how simpler tests are better for explanation. Though, I’m still unsure about the second case study where he originally used a mixed-effect model to investigate the slope parameter between some body measurement and temperature for 53 fishes. His alternative is to run regression for each of the fishes and then average the slope parameter. I actually find the first test to be easier to understand. Hm."
  },
  {
    "objectID": "posts/interesting_paper_week/interestingpaper1.html#how-development-and-survival-combine-to-determine-the-thermal-sensitivity-of-insects",
    "href": "posts/interesting_paper_week/interestingpaper1.html#how-development-and-survival-combine-to-determine-the-thermal-sensitivity-of-insects",
    "title": "Interesting stuff I read (August 12)",
    "section": "How development and survival combine to determine the thermal sensitivity of insects",
    "text": "How development and survival combine to determine the thermal sensitivity of insects\nAbarca et al. 2024\nI really loved this paper because it’s something I’ve been thinking about for a project I’m trying to start. Basically, the premise is that looking at thermal performance curves for mortality and development by themselves say nothing about their performance. For example, in colder areas, development rate can be more of the limiting factor than survivorship. However, in warmer areas, survivorship can be more of the limiting factor. This can be an interesting look at Schmaulhausen law…"
  },
  {
    "objectID": "posts/interesting_paper_week/interestingpaper1.html#diptera-vectors-of-avian-haemosporidian-parasites-untangling-parasite-life-cycles-and-their-taxonomy",
    "href": "posts/interesting_paper_week/interestingpaper1.html#diptera-vectors-of-avian-haemosporidian-parasites-untangling-parasite-life-cycles-and-their-taxonomy",
    "title": "Interesting stuff I read (August 12)",
    "section": "Diptera vectors of avian Haemosporidian parasites: untangling parasite life cycles and their taxonomy",
    "text": "Diptera vectors of avian Haemosporidian parasites: untangling parasite life cycles and their taxonomy\nAlarcon et al. 2012\nReally interesting paper (though I skipped a lot of just to read the Plasmodium part). Shows that a lot of malaria knowledge can be beliefs instead of facts. A plea for more network analysis in parasite/vectors."
  },
  {
    "objectID": "posts/interesting_paper_week/interestingpaper1.html#thermal-biology-of-mosquito-borne-disease",
    "href": "posts/interesting_paper_week/interestingpaper1.html#thermal-biology-of-mosquito-borne-disease",
    "title": "Interesting stuff I read (August 12)",
    "section": "Thermal biology of mosquito-borne disease",
    "text": "Thermal biology of mosquito-borne disease\nMordecai et al. 2019\nTrying to work on a paper about thermal performance curves and trying to figure out what’s been done! Great paper, but makes me want to pull my hair out- what hasn’t been done?"
  },
  {
    "objectID": "posts/interesting_paper_week/interestingpaper1.html#evolution-of-geographic-variation-in-thermal-performance-curves-in-the-face-of-climate-change-and-implications-for-biotic-interactions",
    "href": "posts/interesting_paper_week/interestingpaper1.html#evolution-of-geographic-variation-in-thermal-performance-curves-in-the-face-of-climate-change-and-implications-for-biotic-interactions",
    "title": "Interesting stuff I read (August 12)",
    "section": "Evolution of geographic variation in thermal performance curves in the face of climate change and implications for biotic interactions",
    "text": "Evolution of geographic variation in thermal performance curves in the face of climate change and implications for biotic interactions\nTuzun and Stoks 2018\nHm, wild finding is that thermal performance curves do not vary across geography for a species with wide geographic distribution. The difference in TPC’s seem to be mostly ‘vertical’."
  },
  {
    "objectID": "posts/diff_eq1/diff_eq_1.html",
    "href": "posts/diff_eq1/diff_eq_1.html",
    "title": "Simulating ecology models: A series of tutorial",
    "section": "",
    "text": "WORK In PROGRESS"
  },
  {
    "objectID": "posts/diff_eq1/diff_eq_1.html#introduction",
    "href": "posts/diff_eq1/diff_eq_1.html#introduction",
    "title": "Simulating ecology models: A series of tutorial",
    "section": "Introduction",
    "text": "Introduction\nThis is a simple blog post series for those new to R and modeling ecological models. This series go through the mathematics and the R codes necessary for simulations. This is catered towards someone with experience with ecology but would like a casual introduction to simulation."
  },
  {
    "objectID": "posts/diff_eq1/diff_eq_1.html#lets-start-at-the-very-beginning",
    "href": "posts/diff_eq1/diff_eq_1.html#lets-start-at-the-very-beginning",
    "title": "Simulating ecology models: A series of tutorial",
    "section": "Let’s start at the very beginning",
    "text": "Let’s start at the very beginning\nA very good place to start is with population growth. Ecologists are fascinated by the rise and fall in the organism’s numbers. The simplest question an ecologist may start with: “If I have these initial number of organisms, and each produce this number of offspring, what should the total population be some time later?”\nDifferential equation models are in continuous time which means that the change in the population happens in the small time units. Think of a second, now think of a nanosecond, and think the smallest proportion of that time- the population is changing even within that tiny little time-frame. That may seem far-fetched and for species that reproduce once per season, we should be resorting to discrete time. Generally, people are better about thinking of population growth in discrete time where with each discrete time-step (a day, a week, a month) there is an increase in the population.\nLet us say that our organisms of interest are female rabbits and we describe their population size at time \\(t\\) as \\(N_t\\). Assume that every with each time step, each rabbit births the same number of new rabbits! This parameter is the birth rate \\(b\\). If we have the initial founding number as \\(N_0\\) then we can write that the next time step as:\n\\[\nN_{1} = N_0 + bN_0.\n\\]\nFor example, if there was originally 5 adults (\\(N_0 = 5\\)) and each produces 5 rabbits (\\(b = 5\\)), then we will have 25 new adults. Adding both parents and children, we have \\(N_1 = 5 + (25) = 30\\) Here, we assume that the offspring are adults pretty much instantly. What does this look like for \\(t = 2\\)?\n\\[\nN_{2} = N(1) + 5N(1)\n\\] If we substitute \\(N(1) = 30\\), then we have \\(N_2 = 30 + 150 = 180\\). It is extremely tedious of having to write each time-step seperately (imagine having to do this for a 100 timesteps!)\nBy rearranging the equation, we can see (try it out first!)\n\\[\nN_{1} = N_0(1 + b)\n\\]\n\\[\nN_{2} = N_{1}(1 + b)\n\\]\nThis suggests that:\n\\[\nN_{2} = N_0(1+b)(1+b)\n\\]\nSo how about \\(N_{3}\\) ?\n\\[\nN_{3} = N_{2} (1+b)\n\\]\nWhich is equivalent to:\n\\[\nN_{3} = N_0(1+b)(1+b)(1+b).\n\\]\nThat’s interesting! We basically just need to know the initial starting value (\\(N_0\\)) and we can raise the (1+b) to the power of the time! Here’s a visual cue if you need a bit more help:\nBut to predict the number of rabbits at time \\(t\\), we simply need to know the initial abundance (\\(N_0\\)) and the birth rate (\\(b\\)): \\(N_t = N_0(1+b)^t\\)"
  },
  {
    "objectID": "posts/diff_eq1/diff_eq_1.html#discrete-to-continuous",
    "href": "posts/diff_eq1/diff_eq_1.html#discrete-to-continuous",
    "title": "Simulating ecology models: A series of tutorial",
    "section": "Discrete to Continuous",
    "text": "Discrete to Continuous\nNow how does this relate to the continuous model? The secret is that the continuous model is just the discrete model but we’re making the time step smaller and smaller. Here’s a thought experiment, here I’m assuming that the rabbit is expanding day by day. Nothing about this model is stopping me from thinking of growth every… hour, minute, second, or nanosecond. However, if we want to have a model that is growth every 12 hours instead of 24 hours, we need to adjust \\(b\\) by multiplying it by \\(\\frac{1}{2}\\). If it’s every hour, we need to adjust \\(b\\) by multiplying it by \\(\\frac{1}{24}\\). So ultimately, we multiply \\(b\\) by some time step which we call: \\(\\Delta T\\).\nNow how does the step from discrete to continuous happen? Starting from this, we can move one of the N_0 \\[\nN_{t+1} = N_{t} + bN_{t} \\Delta t.\n\\] \\[\nN_{t+1} - N_t =  b N_t \\Delta t\n\\] \\[\n\\frac{N_{t+1} - N_t}{\\Delta t} = {bN_t}\n\\] As you let \\(\\delta T\\) approach infinity, this discrete equation can then be described as a differential.\n\\[ \\frac{dN}{dt} = {bN_t} \\] Solving it, we get:\n\\[\nN(t) = N_0exp(b(t))\n\\]"
  },
  {
    "objectID": "posts/diff_eq1/diff_eq_1.html#the-exponential-model",
    "href": "posts/diff_eq1/diff_eq_1.html#the-exponential-model",
    "title": "Simulating ecology models: A series of tutorial",
    "section": "The exponential model",
    "text": "The exponential model\nHere, the exponential model returns. Wildly popular, wildly unrealistic, and appears in many aspects. It is the intro ecology student’s first introduction to population growth models.\nLet’s say we have a per-capita growth rate of 5 new rabbits per rabbit per time. In other words:\n$$\n$$\nThat means that \\(r = 5\\)\nSo what does that mean? We know that\n\\[\n\\frac{dN}{dt} =\n\\]\nHow to solve it? So there’s an entire textbook of solving differential equations:\n\\[\nN(t) = N_0 e^{r(t)}\n\\] So aha, we found the analytical solution (which honestly would many models especailly as they become more and more complicated are less likely to have a clean solution).\nMost of the time we have to numerically solve it! Which would be the next section!"
  },
  {
    "objectID": "posts/diff_eq1/diff_eq_1.html#discrete-to-continuous-1",
    "href": "posts/diff_eq1/diff_eq_1.html#discrete-to-continuous-1",
    "title": "Simulating ecology models: A series of tutorial",
    "section": "Discrete to continuous",
    "text": "Discrete to continuous\nSo how does the step to discrete to continuous happen?\n\\[ N\\_{t+1} - N_t = \\Delta T \\space b \\space N_t \\]\n\\[\n\\frac{N_{t+1} - N_t}{\\Delta t} = {bN_t}\n\\]\n\\[\\frac{dN}{dt} = {bN_t} \\]"
  },
  {
    "objectID": "posts/briere/simulating_tpc.html",
    "href": "posts/briere/simulating_tpc.html",
    "title": "Quick how to: Simulating different thermal performance curves",
    "section": "",
    "text": "WORK IN PROGRESS\nFor a project, I’m perhaps interested in modeling different thermal performance curves. Using the Briere function, for example, the equation looks like this:\n\\[\naT(T - T_L)(T_U- T)^{1/d}\n\\]\nas an example\nLet’s say T goes from 10 to 30 Celsius. a and d are parameters that are to be estimated.\n\nTemperature_range = seq(0,40)\na = 0.1\nTL = 10\nTU = 35\nd = 2\n\n\neef &lt;- a * Temperature_range * (Temperature_range - TL) * (TU -Temperature_range)^(1/d)\n\n\nplot(Temperature_range, eef)\n\n\n\n\n\n\n\n\n```{r}"
  },
  {
    "objectID": "posts/diff_eq2/diff_eq_2.html",
    "href": "posts/diff_eq2/diff_eq_2.html",
    "title": "Simulating ecology models: A series of tutorial (Part 2)",
    "section": "",
    "text": "WORK IN PROGRESS\nSo in the previous section, we talked about the simplest differential equation which is population growth: both continuous and discrete. We found the analytically solutions but unfortunately most equations are not easy to solve by hand! We need to use numerical methods.\nThe easiest method is by our favorite mathematician man: Leonard Euler. His method of calculating the"
  },
  {
    "objectID": "posts/simulate_scale_free_network/simulatenetwork.html",
    "href": "posts/simulate_scale_free_network/simulatenetwork.html",
    "title": "Simulating a scale-free network",
    "section": "",
    "text": "library(igraph)\nlibrary(ggplot2)\nlibrary(reshape2)\nset.seed(24601)"
  },
  {
    "objectID": "posts/simulate_scale_free_network/simulatenetwork.html#an-introduction",
    "href": "posts/simulate_scale_free_network/simulatenetwork.html#an-introduction",
    "title": "Simulating a scale-free network",
    "section": "An introduction",
    "text": "An introduction\nNote: I have done a much better way (but I have left this up as a historical relic)\nThe goal is to create a spatial network that is scale-free with the user having the ability to vary the connectance. Assuming that \\(n\\) is the number of patches and \\(l\\) is the number of edges,the connectance (\\(C\\)) is then: \\(\\frac{l}{n^2}\\)."
  },
  {
    "objectID": "posts/simulate_scale_free_network/simulatenetwork.html#calculate-the-maximum-connectance-from-the-number-of-nodes-n",
    "href": "posts/simulate_scale_free_network/simulatenetwork.html#calculate-the-maximum-connectance-from-the-number-of-nodes-n",
    "title": "Simulating a scale-free network",
    "section": "Calculate the maximum connectance from the number of nodes, \\(n\\)",
    "text": "Calculate the maximum connectance from the number of nodes, \\(n\\)"
  },
  {
    "objectID": "posts/simulate_scale_free_network/simulatenetwork.html#size-of-the-network-and-connectance",
    "href": "posts/simulate_scale_free_network/simulatenetwork.html#size-of-the-network-and-connectance",
    "title": "Simulating a scale-free network",
    "section": "Size of the network and connectance",
    "text": "Size of the network and connectance\nThe number of patches then determines the minimum and maximum number of edges possible. In an undirected graph, the minimum number of edges we can have is \\(n-1\\) . For the maximum number of edges: \\(n \\frac{(n-1)}{2}\\). With both the number of patches and edges, we can then calculate the minimum and maximum value of connectance.\nFor example, if we have 20 patches (\\(n = 20\\)):\n\nn = 20\nmin_edge = n - 1 # 19\nmax_edge = n * (n-1)/2 # 190 \n\nWith the minimum and maximum number of edges being 19 and 190 respectfully, the minimum and maximum connectances are:\n\nc(min_edge/(n^2), max_edge/(n^2))\n\n[1] 0.0475 0.4750\n\n\nHere is a short function to calculate connectivity when given a network:\n\n###Put an igraph network \ncalculate_connectivity &lt;- function(network){\n  \n  nodes =  vcount(network) #Code the number of vertex/patch/node\n  edges = ecount(network) #Count the number of edges\n  return(edges/(nodes^2)) #Return the connectance\n  \n}\n\nTherefore, with a given number of patches, I can calculate the number of edges needed to get the specific value of connectance."
  },
  {
    "objectID": "posts/simulate_scale_free_network/simulatenetwork.html#first-create-coordinates",
    "href": "posts/simulate_scale_free_network/simulatenetwork.html#first-create-coordinates",
    "title": "Simulating a scale-free network",
    "section": "First, create coordinates",
    "text": "First, create coordinates"
  },
  {
    "objectID": "posts/simulate_scale_free_network/simulatenetwork.html#first-calculate-the-maximum-connectance-from-the-number-of-nodes-n",
    "href": "posts/simulate_scale_free_network/simulatenetwork.html#first-calculate-the-maximum-connectance-from-the-number-of-nodes-n",
    "title": "Simulating a scale-free network",
    "section": "First, calculate the maximum connectance from the number of nodes, \\(n\\)",
    "text": "First, calculate the maximum connectance from the number of nodes, \\(n\\)\n\ncalculate_maximum_connectance &lt;- function(n){\n  max_edges &lt;- n * (n-1)/2 \n\n  return(max_edges/(n^2))\n}\n\nNow what is the lowest number of \\(m\\) does it have to to be for the highest connectance? I test this alot and it seems to be \\(n-1\\), makes sense.\nSo here we can get some ideas:\n\nm_vec &lt;-seq(1,n-1)\nlist_network = NULL\nfor (i in seq(1,length(m_vec))){\n  \n  \n net&lt;- sample_pa(n,directed = FALSE, m = m_vec [[i]], algorithm = \"psumtree\")\n \n \nlist_network[[i]]= data.frame(connectivity = calculate_connectivity(net),\n                     edges =ecount(net))\n\n\n}\ndf_network &lt;- do.call(rbind, list_network)\n\n\nCreate a series of networks with the right connectivity\n\nrand_vect &lt;- function(N, M, sd = 1, pos.only = TRUE) {\n  vec &lt;- rnorm(N, M/N, sd)\n  if (abs(sum(vec)) &lt; 0.01) vec &lt;- vec + 1\n  vec &lt;- round(vec / sum(vec) * M)\n  deviation &lt;- M - sum(vec)\n  for (. in seq_len(abs(deviation))) {\n    vec[i] &lt;- vec[i &lt;- sample(N, 1)] + sign(deviation)\n  }\n  if (pos.only) while (any(vec &lt; 0)) {\n    negs &lt;- vec &lt; 0\n    pos  &lt;- vec &gt; 0\n    vec[negs][i] &lt;- vec[negs][i &lt;- sample(sum(negs), 1)] + 1\n    vec[pos][i]  &lt;- vec[pos ][i &lt;- sample(sum(pos ), 1)] - 1\n  }\n  vec\n}\n\n\ngenOutSeq &lt;- function(n, m) {\n  n &lt;- n-1 # Shift it along\n  rem &lt;- m %% n\n  c(0, rep(m%/%n + 1, rem), rep(m%/%n, n - rem))\n  \n}"
  },
  {
    "objectID": "posts/simulate_scale_free_network/simulatenetwork.html#simulating-creating-spatial-coordinates",
    "href": "posts/simulate_scale_free_network/simulatenetwork.html#simulating-creating-spatial-coordinates",
    "title": "Simulating a scale-free network",
    "section": "Simulating creating spatial coordinates",
    "text": "Simulating creating spatial coordinates\nFirst, we create a spatial network. We sample the coordinates from a uniform distribution with a maximum distance:\n\nx.coordinates &lt;- runif(n,0,10)\ny.coordinates &lt;- runif(n,0,10)\npoints &lt;- cbind(x.coordinates,y.coordinates)\n\n\n\n\n\n\n\n\n\n\nI’m, however, more interested in getting the distances between points.\n\ndistance_matrix &lt;- as.matrix(dist(points))\n\nThis gives us a matrix that has the distances between points."
  },
  {
    "objectID": "posts/simulate_scale_free_network/simulatenetwork.html#for-each-connectance-value-calculate-the-number-of-edges",
    "href": "posts/simulate_scale_free_network/simulatenetwork.html#for-each-connectance-value-calculate-the-number-of-edges",
    "title": "Simulating a scale-free network",
    "section": "For each connectance value, calculate the number of edges",
    "text": "For each connectance value, calculate the number of edges\nThis is a function to calculate the number of edges. I want to get connectance values of 0.05, 0.10, 0.20, 0.30, and 0.40. Then the total number of edges needed based on the patch number is: \\(C n^2\\)\n\ncalculate_edge &lt;- function(n){\n  connectance  = c(0.05,0.10,0.20,0.30,0.40) #good ranges?\n  \n   return(connectance * n^2)\n}\n\nTherefore, if I want to create a network with this connectance value, here are the number of edges that I need:\n\ncbind.data.frame(connectance = c(0.05,0.10, 0.20, 0.30,0.40),\n                 edges = calculate_edge(20))\n\n  connectance edges\n1        0.05    20\n2        0.10    40\n3        0.20    80\n4        0.30   120\n5        0.40   160"
  },
  {
    "objectID": "posts/simulate_scale_free_network/simulatenetwork.html#using-barabásialbert-for-preferential-attachment",
    "href": "posts/simulate_scale_free_network/simulatenetwork.html#using-barabásialbert-for-preferential-attachment",
    "title": "Simulating a scale-free network",
    "section": "Using Barabási–Albert for preferential attachment",
    "text": "Using Barabási–Albert for preferential attachment\nI’m assuming that the spatial network is scale-free (Need to find more references to verify this). I don’t think this is a bad assumption. In igraph, to create a scale-free network with preferential attachment, we uses sample_pa. In this stochastic algorithm, you add new nodes and edges with each time step.\nThe only way to manipulate the total number of edges you want is by using the “out_seq” argment which states: Numeric vector giving the number of edges to add in each time step. Its first element is ignored as no edges are added in the first time step”. Therefore, you can ensure that you have the right number of edges added by summing the vector.\nHere, is a function that lets me generate a number of edges to be added with each time step (I took code from this stackoverflow post) (Source: Generate Random network models with specified number of edges).\n\ngenOutSeq &lt;- function(n, m) {\n  n &lt;- n-1 # Shift it along\n  rem &lt;- m %% n\n  c(0, rep(m%/%n + 1, rem), rep(m%/%n, n - rem))\n  \n}\n\n\n### The out_seq to be put into the network.\nedges_list &lt;-  lapply(calculate_edge (20),  function(x) genOutSeq(n,x))\n\n\nadjacency_matrix_list &lt;- list()\n\nfor (k in seq(1,length(edges_list))){\n\nnet &lt;- sample_pa(\n  n, #Number of patches\n  power = 1,\n  out.seq = edges_list[[k]], #This is the vector list\n  zero.appeal = 1,\n  directed = FALSE, #undirected\n  algorithm = c(\"psumtree\"), #Prevents multiedges\n  start.graph = NULL)\n\n\n###It is possible that I don't have the right number of edges\n###so I must randomly add edges if there are some missing\nnMulti &lt;- sum(edges_list[[k]]) - gsize(net)\n\n\n### We basically run this until we have the correct number of edges AND\n### there are no mutliedges\nwhile(is_simple(net) == FALSE){\nfor (i in 1:nMulti) {\n  vPair &lt;- sample(1:n, size = 2)\n  net &lt;- add_edges(net, vPair)\n  \n  net &lt;- simplify(net,\n  remove.multiple = TRUE,\n  remove.loops = TRUE)\n}\n}\n\n###Convert graph to adjacency matrix\nadj_matrix &lt;- as_adjacency_matrix(\n  net,\n  type = c(\"both\"),\nsparse = \"false\")\n\n### Save adjacency matrix ot a list\nadjacency_matrix_list[[k]] &lt;- as.matrix(adj_matrix)\n}"
  },
  {
    "objectID": "posts/simulate_scale_free_network/simulatenetwork.html#combining-the-spatial-distances-and-the-network",
    "href": "posts/simulate_scale_free_network/simulatenetwork.html#combining-the-spatial-distances-and-the-network",
    "title": "Simulating a scale-free network",
    "section": "Combining the spatial distances and the network",
    "text": "Combining the spatial distances and the network\nTaking the idea from the previous section, I realized that I should simulate the same network with various distances between the patches.\n\ngenerate_distance_matrix &lt;- function(n, max_distance){\n  x.coordinates &lt;- runif(n,0,max_distance)\n  y.coordinates &lt;- runif(n,0,max_distance)\n  points &lt;- cbind(x.coordinates,y.coordinates)\n  distance_matrix &lt;- as.matrix(dist(points))\n  \n  return(distance_matrix)\n  \n  \n}\ngenerate_distance_matrix(20,16)\n\n            1          2         3         4         5          6          7\n1   0.0000000  8.6175165 11.655109  9.112391  6.404841  5.9089007  6.0997858\n2   8.6175165  0.0000000 10.990153 14.130475 13.908119  6.3941861  2.7532546\n3  11.6551087 10.9901532  0.000000  7.820306 11.376322 14.8731465  9.5424053\n4   9.1123912 14.1304746  7.820306  0.000000  4.730953 14.6410196 11.5533601\n5   6.4048412 13.9081193 11.376322  4.730953  0.000000 12.3096419 11.1552559\n6   5.9089007  6.3941861 14.873147 14.641020 12.309642  0.0000000  5.7051202\n7   6.0997858  2.7532546  9.542405 11.553360 11.155256  5.7051202  0.0000000\n8  10.0615160 11.8957354  3.261227  4.563092  8.419182 14.3881948  9.8094469\n9   6.3298472  5.7468549 14.667616 14.844755 12.730002  0.7722736  5.3193032\n10  1.5206241 10.1114869 12.131785  8.522742  5.200992  7.1917517  7.5432196\n11  4.8569345 13.4652417 14.206410  8.732522  4.161066 10.0078166 10.8847605\n12 14.2192858 15.9176823  5.346523  6.586582 11.282209 18.7242766 14.0282542\n13  5.5689979  6.5125511 14.728153 14.347009 11.966004  0.3603898  5.6672092\n14  3.7912128 11.6638534 11.147016  6.172511  2.616587  9.6932863  8.9368108\n15  8.1779382  0.5785997 10.506733 13.551950 13.367012  6.3453653  2.2160576\n16  0.7136292  9.0261390 12.364270  9.598716  6.589343  5.7670339  6.5971229\n17  6.5508088  2.4267505  9.421134 11.760379 11.510713  6.0288071  0.4617598\n18  6.9659857  3.3330187  7.988477 10.887960 11.188305  7.3829891  1.6842108\n19 10.5529303  9.0708803  1.935084  8.455247 11.322822 13.2246967  7.7493002\n20  8.7900665  7.9959965  3.269103  7.709081  9.974725 11.6095843  6.3086001\n           8          9        10        11        12         13        14\n1  10.061516  6.3298472  1.520624  4.856934 14.219286  5.5689979  3.791213\n2  11.895735  5.7468549 10.111487 13.465242 15.917682  6.5125511 11.663853\n3   3.261227 14.6676164 12.131785 14.206410  5.346523 14.7281532 11.147016\n4   4.563092 14.8447547  8.522742  8.732522  6.586582 14.3470087  6.172511\n5   8.419182 12.7300016  5.200992  4.161066 11.282209 11.9660036  2.616587\n6  14.388195  0.7722736  7.191752 10.007817 18.724277  0.3603898  9.693286\n7   9.809447  5.3193032  7.543220 10.884761 14.028254  5.6672092  8.936811\n8   0.000000 14.3520920 10.166707 11.685433  4.336181 14.1741402  8.658880\n9  14.352092  0.0000000  7.682566 10.606512 18.684757  1.0699966 10.120062\n10 10.166707  7.6825665  0.000000  3.353893 14.134935  6.8391626  2.624882\n11 11.685433 10.6065121  3.353893  0.000000 15.105187  9.6474534  3.061283\n12  4.336181 18.6847568 14.134935 15.105187  0.000000 18.5090168 12.250093\n13 14.174140  1.0699966  6.839163  9.647453 18.509017  0.0000000  9.349431\n14  8.658880 10.1200616  2.624882  3.061283 12.250093  9.3494305  0.000000\n15 11.342895  5.7411839  9.659216 13.012267 15.388788  6.4328025 11.148412\n16 10.727791  6.2603784  1.425149  4.558631 14.855356  5.4149740  3.983245\n17  9.842589  5.6026458  7.986216 11.323122 14.018737  6.0105001  9.329770\n18  8.587498  7.0031835  8.280557 11.530830 12.687169  7.3344379  9.230654\n19  4.194378 12.9678057 11.234096 13.657904  7.185773 13.1045056 10.649714\n20  4.114967 11.3985156  9.503237 12.029807  7.923987 11.4704602  9.065163\n           15         16         17        18        19        20\n1   8.1779382  0.7136292  6.5508088  6.965986 10.552930  8.790067\n2   0.5785997  9.0261390  2.4267505  3.333019  9.070880  7.995997\n3  10.5067329 12.3642701  9.4211339  7.988477  1.935084  3.269103\n4  13.5519503  9.5987161 11.7603787 10.887960  8.455247  7.709081\n5  13.3670124  6.5893427 11.5107129 11.188305 11.322822  9.974725\n6   6.3453653  5.7670339  6.0288071  7.382989 13.224697 11.609584\n7   2.2160576  6.5971229  0.4617598  1.684211  7.749300  6.308600\n8  11.3428955 10.7277914  9.8425893  8.587498  4.194378  4.114967\n9   5.7411839  6.2603784  5.6026458  7.003183 12.967806 11.398516\n10  9.6592164  1.4251494  7.9862156  8.280557 11.234096  9.503237\n11 13.0122669  4.5586309 11.3231218 11.530830 13.657904 12.029807\n12 15.3887880 14.8553558 14.0187369 12.687169  7.185773  7.923987\n13  6.4328025  5.4149740  6.0105001  7.334438 13.104506 11.470460\n14 11.1484123  3.9832452  9.3297702  9.230654 10.649714  9.065163\n15  0.0000000  8.6127032  1.8652457  2.766816  8.596757  7.473197\n16  8.6127032  0.0000000  7.0544556  7.558628 11.266294  9.503158\n17  1.8652457  7.0544556  0.0000000  1.452262  7.592865  6.220783\n18  2.7668161  7.5586280  1.4522615  0.000000  6.145836  4.821852\n19  8.5967575 11.2662935  7.5928649  6.145836  0.000000  1.766750\n20  7.4731970  9.5031579  6.2207827  4.821852  1.766750  0.000000\n\n\n\n### Generate a 5 distance matrix\n\ndistance_matrices&lt;- replicate(5,generate_distance_matrix(20,16),simplify=FALSE)\n\n\nspatial_scale_free_network &lt;- NULL\n\n\nfor (i in seq(1,length(adjacency_matrix_list))){\n  \n  adjacency_matrix_list_Interest &lt;-  adjacency_matrix_list [[i]] \n  \n  spatial_scale_free_network [[i]] &lt;- lapply(distance_matrices, function(x) x *  adjacency_matrix_list_Interest)\n        \n\n}\n\nLet’s plot it out:\n\ngraph_low_connectance&lt;-   lapply(\nspatial_scale_free_network[[1]],function(x)\ngraph_from_adjacency_matrix(x, mode = \n                            \"undirected\", weighted= \"TRUE\"))\n\n\npar(mfrow=c(3,2))\n\nfor (i in seq(1,5)){\n  plot(graph_low_connectance[[i]])\n}\n\n\n\n\n\n\n\n\n}"
  },
  {
    "objectID": "posts/simulate_scale_free_network/simulatenetwork.html#combining-the-spatial-distances-and-the-scale-free-network",
    "href": "posts/simulate_scale_free_network/simulatenetwork.html#combining-the-spatial-distances-and-the-scale-free-network",
    "title": "Simulating a scale-free network",
    "section": "Combining the spatial distances and the scale-free network",
    "text": "Combining the spatial distances and the scale-free network\nI realized that I should simulate the same network with various distances between the patches.\n\n###This generates the distance matrices between patches\ngenerate_distance_matrix &lt;- function(n, max_distance){\n  x.coordinates &lt;- runif(n,0,max_distance)\n  y.coordinates &lt;- runif(n,0,max_distance)\n  points &lt;- cbind(x.coordinates,y.coordinates)\n  distance_matrix &lt;- as.matrix(dist(points))\n  \n  return(distance_matrix)\n  \n}\ngenerate_distance_matrix(20,16)\n\n           1         2         3         4         5          6         7\n1   0.000000  5.157415 15.193534  6.956727 10.595116 11.0874552 11.626523\n2   5.157415  0.000000 12.584992  2.113439  7.126970 13.1673740  9.468252\n3  15.193534 12.584992  0.000000 10.849847  5.601309 11.9520194  3.604385\n4   6.956727  2.113439 10.849847  0.000000  5.273883 13.2341047  8.008133\n5  10.595116  7.126970  5.601309  5.273883  0.000000 11.7723962  3.387007\n6  11.087455 13.167374 11.952019 13.234105 11.772396  0.0000000  9.433731\n7  11.626523  9.468252  3.604385  8.008133  3.387007  9.4337309  0.000000\n8   4.873067  2.974354 10.609897  3.173989  5.727345 10.2786557  7.181685\n9  14.337942 10.288828  5.060660  8.208842  3.892680 14.9467973  5.563506\n10  9.978614  4.826225 11.473110  3.284642  6.138704 16.1859300  9.464290\n11  2.330038  4.518944 12.907996  5.762383  8.536265  9.4506963  9.325471\n12  7.855760  5.708047  7.382344  4.647664  3.186196  9.2709702  3.922495\n13  5.868926  2.873714  9.966747  2.343386  4.823247 10.8959945  6.683709\n14 13.941346 14.882039  9.894034 14.411544 11.511777  3.8356737  8.440559\n15 11.518690 13.523889 11.903111 13.544006 11.931739  0.4457247  9.495183\n16 12.320441 10.815616  3.780814  9.545150  5.198992  8.2663361  1.822419\n17 10.769585  8.458042  4.425673  6.997295  2.596253  9.5504748  1.014959\n18 13.825584 15.428669 11.728347 15.210645 12.855849  2.8619062  9.980735\n19  6.031332  4.818469  9.162611  4.490833  4.960311  8.7478925  5.609609\n20 10.288681 11.010526  8.654084 10.636661  8.434724  3.4550483  5.979122\n           8         9        10        11        12        13        14\n1   4.873067 14.337942  9.978614  2.330038  7.855760  5.868926 13.941346\n2   2.974354 10.288828  4.826225  4.518944  5.708047  2.873714 14.882039\n3  10.609897  5.060660 11.473110 12.907996  7.382344  9.966747  9.894034\n4   3.173989  8.208842  3.284642  5.762383  4.647664  2.343386 14.411544\n5   5.727345  3.892680  6.138704  8.536265  3.186196  4.823247 11.511777\n6  10.278656 14.946797 16.185930  9.450696  9.270970 10.895994  3.835674\n7   7.181685  5.563506  9.464290  9.325471  3.922495  6.683709  8.440559\n8   0.000000  9.475056  6.432780  2.983490  3.259538  1.101142 11.909801\n9   9.475056  0.000000  7.503353 12.369914  7.064457  8.475221 13.900773\n10  6.432780  7.503353  0.000000  9.016932  7.072227  5.493291 16.923081\n11  2.983490 12.369914  9.016932  0.000000  5.631318  4.078112 11.958847\n12  3.259538  7.064457  7.072227  5.631318  0.000000  2.843700  9.879585\n13  1.101142  8.475221  5.493291  4.078112  2.843700  0.000000 12.214657\n14 11.909801 13.900773 16.923081 11.958847  9.879585 12.214657  0.000000\n15 10.619311 15.032079 16.462386  9.858851  9.506757 11.210803  3.471485\n16  8.265301  7.118348 11.224512  9.990403  5.113260  7.956910  6.782439\n17  6.227417  5.421074  8.549443  8.492820  2.973592  5.688215  8.954794\n18 12.468831 15.518238 17.932983 12.048341 10.864687 12.926205  1.934995\n19  1.896866  8.852179  7.497992  3.768494  1.878649  2.170724 10.088460\n20  8.036498 11.497423 13.321285  8.190764  6.254737  8.388567  3.880907\n           15        16        17        18        19        20\n1  11.5186899 12.320441 10.769585 13.825584  6.031332 10.288681\n2  13.5238889 10.815616  8.458042 15.428669  4.818469 11.010526\n3  11.9031106  3.780814  4.425673 11.728347  9.162611  8.654084\n4  13.5440064  9.545150  6.997295 15.210645  4.490833 10.636661\n5  11.9317388  5.198992  2.596253 12.855849  4.960311  8.434724\n6   0.4457247  8.266336  9.550475  2.861906  8.747892  3.455048\n7   9.4951835  1.822419  1.014959  9.980735  5.609609  5.979122\n8  10.6193112  8.265301  6.227417 12.468831  1.896866  8.036498\n9  15.0320794  7.118348  5.421074 15.518238  8.852179 11.497423\n10 16.4623864 11.224512  8.549443 17.932983  7.497992 13.321285\n11  9.8588514  9.990403  8.492820 12.048341  3.768494  8.190764\n12  9.5067573  5.113260  2.973592 10.864687  1.878649  6.254737\n13 11.2108027  7.956910  5.688215 12.926205  2.170724  8.388567\n14  3.4714848  6.782439  8.954794  1.934995 10.088460  3.880907\n15  0.0000000  8.258882  9.658070  2.417472  9.053737  3.539507\n16  8.2588825  0.000000  2.675237  8.435509  6.495927  4.897432\n17  9.6580700  2.675237  0.000000 10.374968  4.738255  6.119064\n18  2.4174721  8.435509 10.374968  0.000000 10.757652  4.611757\n19  9.0537368  6.495927  4.738255 10.757652  0.000000  6.238836\n20  3.5395065  4.897432  6.119064  4.611757  6.238836  0.000000\n\n\n\n### Generate 5 distance matrix - ideally i should have a large number of simulated distance matrices (n = 1000)\ndistance_matrices&lt;- replicate(5,generate_distance_matrix(20,16),simplify=FALSE)\n\nThis code is to basically take the adjacency matrix that we created earlier with varying connectance and multiply it by the distance matrix.\n\nspatial_scale_free_network &lt;- NULL\n\nfor (i in seq(1, length(adjacency_matrix_list))) {\n  adjacency_matrix_list_Interest &lt;- adjacency_matrix_list[[i]]\n\n  spatial_scale_free_network[[i]] &lt;- lapply(distance_matrices, function(x) x * adjacency_matrix_list_Interest)\n}\n\nLet’s plot it out. Here we are looking at the adjaceny matrix associated with low connectance.\n\ngraph_low_connectance&lt;-   lapply(\nspatial_scale_free_network[[1]],function(x)\ngraph_from_adjacency_matrix(x, mode = \n                            \"undirected\", \n                            weighted= \"TRUE\"))\n\nOk, you should be able to see different distances between patches.\n\npar(mfrow=c(3,2))\nfor (i in seq(1,5)){\n  plot(graph_low_connectance[[i]],layout=layout.auto)\n}\n\n\n\n\n\n\n\n\nHere is a high connectance one:\n\ngraph_high_connectance&lt;-   lapply(\nspatial_scale_free_network[[5]],function(x)\ngraph_from_adjacency_matrix(x, mode = \n                            \"undirected\", weighted= \"TRUE\"))\n\n\npar(mfrow=c(3,2))\n\nfor (i in seq(1,5)){\n  plot(graph_high_connectance[[i]],layout=layout.auto)\n}"
  },
  {
    "objectID": "posts/interesting_paper_week2/interesting_paperweek2.html",
    "href": "posts/interesting_paper_week2/interesting_paperweek2.html",
    "title": "Interesting stuff I read (August 19th)",
    "section": "",
    "text": "Hereford 2017\nInteresting paper where I learned about MSDM (mechanical species distribution modeling). Mostly experimental, but the paper explores the thermal performance curves (TPCs) of differing genotype in Mollugo verticillata in California. Interestingly, they found that thermal breadth is negatively correlated with optimum temperature. Being more fit in warmer temperature comes at a cost of breadth. A question that I am curious about : is variation in TPC adaptive?"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/Untitled.html",
    "href": "posts/interesting_stuff_I_learned/Untitled.html",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "",
    "text": "This is a list of things I learned. Generally involves my research, but you might see a weird aside."
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/Untitled.html#i-learned-that-its-michelle-pfeiffer-who-played-ambers-mom-in-the-movie-adaptation-of-hairspray-2007",
    "href": "posts/interesting_stuff_I_learned/Untitled.html#i-learned-that-its-michelle-pfeiffer-who-played-ambers-mom-in-the-movie-adaptation-of-hairspray-2007",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "I learned that it’s Michelle Pfeiffer who played Amber’s mom in the movie adaptation of Hairspray (2007)",
    "text": "I learned that it’s Michelle Pfeiffer who played Amber’s mom in the movie adaptation of Hairspray (2007)\nAnd not Hannah Waddingham? I do not feel bad about this mistake- look it up!"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/Untitled.html#profvis-is-a-cool-package-that-helps-you-visualize-profiling-your-code",
    "href": "posts/interesting_stuff_I_learned/Untitled.html#profvis-is-a-cool-package-that-helps-you-visualize-profiling-your-code",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "profvis is a cool package that helps you visualize profiling your code",
    "text": "profvis is a cool package that helps you visualize profiling your code\nAnd figure out where the slowdowns. I learned that the slowdowns are not exactly where I thought they would be?"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/Untitled.html#you-can-save-some-miliseconds-using-rep_length-instead-of-rep",
    "href": "posts/interesting_stuff_I_learned/Untitled.html#you-can-save-some-miliseconds-using-rep_length-instead-of-rep",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "You can save some miliseconds using rep_length instead of rep",
    "text": "You can save some miliseconds using rep_length instead of rep"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/Untitled.html#apply-can-be-slow",
    "href": "posts/interesting_stuff_I_learned/Untitled.html#apply-can-be-slow",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "Apply can be slow",
    "text": "Apply can be slow\nI’m still trying to figure this out."
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/Untitled.html#save-some-miliseconds-using-rep_length-instead-of-rep",
    "href": "posts/interesting_stuff_I_learned/Untitled.html#save-some-miliseconds-using-rep_length-instead-of-rep",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "Save some miliseconds using rep_length instead of rep",
    "text": "Save some miliseconds using rep_length instead of rep\nSame function, but somehow it saves you a few seconds?"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/Untitled.html#you-can-create-sparse-matrix-using-the-package-matrix",
    "href": "posts/interesting_stuff_I_learned/Untitled.html#you-can-create-sparse-matrix-using-the-package-matrix",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "You can create sparse Matrix using the package Matrix",
    "text": "You can create sparse Matrix using the package Matrix\nI didn’t realize how much a dense matrix that is only 20 x 20 can still be slow?"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/Untitled.html#michelle-pfeiffer-plays-ambers-mom-in-the-movie-adaptation-of-hairspray-2007",
    "href": "posts/interesting_stuff_I_learned/Untitled.html#michelle-pfeiffer-plays-ambers-mom-in-the-movie-adaptation-of-hairspray-2007",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "Michelle Pfeiffer plays Amber’s mom in the movie adaptation of Hairspray (2007)",
    "text": "Michelle Pfeiffer plays Amber’s mom in the movie adaptation of Hairspray (2007)\nAnd not Hannah Waddingham. I do not feel bad about this mistake- look it up!"
  },
  {
    "objectID": "posts/interesting_paper_week2/interesting_paperweek2.html#climate-sensitivity-across-latitude-scaling-physiology-to-communities",
    "href": "posts/interesting_paper_week2/interesting_paperweek2.html#climate-sensitivity-across-latitude-scaling-physiology-to-communities",
    "title": "Interesting stuff I read (August 19th)",
    "section": "Climate sensitivity across latitude: scaling physiology to communities",
    "text": "Climate sensitivity across latitude: scaling physiology to communities\nLouthan et al. 2021\nA nice review paper that I really love. It talks about TPCs and how they affect individuals and communities. For example, shapes of TPCs can vary across latitudes due to trade-offs. This can then scale up to affect the community and influence stability. Don’t let the short paragraph deter you, I really recommend."
  },
  {
    "objectID": "posts/interesting_paper_week2/interesting_paperweek2.html#the-failure-of-r_0",
    "href": "posts/interesting_paper_week2/interesting_paperweek2.html#the-failure-of-r_0",
    "title": "Interesting stuff I read (August 19th)",
    "section": "The Failure of \\(R_0\\)",
    "text": "The Failure of \\(R_0\\)\nLi et al. 2001\nA bit of a concerning and eye-opening paper about how \\(R_0\\) is kinda nebulous and that different methods of calculating \\(R_0\\) lead to varying answers (Wild to me!). Talks about how \\(R_0\\) is flawed, but is the best we got. Interesting paper, points out some of the critical failures in the next generation method and such."
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html",
    "href": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "",
    "text": "This is a list of things I learned. Generally involves my research, but you might see a weird aside."
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html#profvis-is-a-cool-package-that-helps-you-visualize-profiling-your-code",
    "href": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html#profvis-is-a-cool-package-that-helps-you-visualize-profiling-your-code",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "profvis is a cool package that helps you visualize profiling your code",
    "text": "profvis is a cool package that helps you visualize profiling your code\nAnd figure out where the slowdowns. I learned that the slowdowns are not exactly where I thought they would be?"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html#save-some-miliseconds-using-rep_length-instead-of-rep",
    "href": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html#save-some-miliseconds-using-rep_length-instead-of-rep",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "Save some miliseconds using rep_length instead of rep",
    "text": "Save some miliseconds using rep_length instead of rep\nSame function, but somehow it saves you a few seconds?"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html#apply-can-be-slow",
    "href": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html#apply-can-be-slow",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "Apply can be slow",
    "text": "Apply can be slow\nI’m still trying to figure this out."
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html#you-can-create-sparse-matrix-using-the-package-matrix",
    "href": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html#you-can-create-sparse-matrix-using-the-package-matrix",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "You can create sparse Matrix using the package Matrix",
    "text": "You can create sparse Matrix using the package Matrix\nI didn’t realize how much a dense matrix that is only 20 x 20 can still be slow?"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html#michelle-pfeiffer-plays-ambers-mom-in-the-movie-adaptation-of-hairspray-2007",
    "href": "posts/interesting_stuff_I_learned/stuffilearnedpart1.html#michelle-pfeiffer-plays-ambers-mom-in-the-movie-adaptation-of-hairspray-2007",
    "title": "Interesting things I learned this week (August 19th)",
    "section": "Michelle Pfeiffer plays Amber’s mom in the movie adaptation of Hairspray (2007)",
    "text": "Michelle Pfeiffer plays Amber’s mom in the movie adaptation of Hairspray (2007)\nAnd not Hannah Waddingham. I do not feel bad about this mistake- look it up!"
  },
  {
    "objectID": "posts/diff_eq1/diff_eq_1.html#coding-it-up",
    "href": "posts/diff_eq1/diff_eq_1.html#coding-it-up",
    "title": "Simulating ecology models: A series of tutorial",
    "section": "Coding it up",
    "text": "Coding it up\nLet’s write a simple code. Please skip to the next section if you are comfortable with creating R functions. Hopefully, my little code will help transition readers into using desolve. Lets go step by step. Personally, I think beginners should start with learning functions as quickly as possible.\nSo how do you design a function for doing mathematical simulations? First, what do you want for your inputs? What are the parts of the model you want to vary? Well, time seems to make the most sense. Maybe I’m interested in seeing what happens in a week… or a thousand years later. The initial rabbit population (\\(N_0\\)) can also vary as well as the birth rate \\(b\\)! So for the input of the function, you should include the parameters that you’re interested in varying.\n\nrabbit_growth &lt;- function(time, initial, b){\n  \n  ###Insert model here\n}\n\nSo I have a function called “rabbit_growth” and for input, it takes that time, initial value, and the birth rate. By feeding different values in, we should be getting different values out!\nNow what do we want for the output? For simulation outputs, we want both the time and the abundance at that time. So ‘time’ is the number of days we are interested in projecting the model out to. Let’s say we want 20 days. We can then create a vector called timesteps that goes from 0 to 20, in an increment of a day. Now we have the equation with the initial value and the birth rate (\\(b\\)). We can raise it to the power of the timesteps. So \\(N_0 * (1+b)^t\\) will you give a single numeric value. But multiplying it by a vector, R is smart to know that you want to multiply \\(N_0 *(1+b)\\) to each element of the vector. For example:\n\ntimesteps = seq(0,20)\nprint(timesteps)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n\n\nprint(paste(\"Single number:\", 5 * (1+5))) # single numeric number #vector\n\n[1] \"Single number: 30\"\n\n\n\n5 * (1+5)^(timesteps) # a vector\n\n [1] 5.000000e+00 3.000000e+01 1.800000e+02 1.080000e+03 6.480000e+03\n [6] 3.888000e+04 2.332800e+05 1.399680e+06 8.398080e+06 5.038848e+07\n[11] 3.023309e+08 1.813985e+09 1.088391e+10 6.530347e+10 3.918208e+11\n[16] 2.350925e+12 1.410555e+13 8.463330e+13 5.077998e+14 3.046799e+15\n[21] 1.828079e+16\n\n\nPutting it all together, here is the completed functino.\n\nrabbit_growth &lt;- function(time, initial, b){\n\n  timesteps =  seq(0,time)\n  \n  abundance  = initial * (1+b)^(timesteps)\n    \n  ###Try to keep the parameter that you are varying as a column for easier analysis \n  rabbit_df &lt;- data.frame(time = timesteps, abundance = abundance,\n                          initial = initial, b = b)\n    \n  return(rabbit_df)\n  }\n\nMy output is now a data.frame with the time, abundance, initial value, and birth rate.\nThere are many, many ways to solve this. Some people do for-loops! IF you want to do it using for-loop, this is a perfect exercise for it! Now let’s plot it.\n\nstandard_rabbit &lt;- rabbit_growth(10,5, 1)\nprint(standard_rabbit)\n\n   time abundance initial b\n1     0         5       5 1\n2     1        10       5 1\n3     2        20       5 1\n4     3        40       5 1\n5     4        80       5 1\n6     5       160       5 1\n7     6       320       5 1\n8     7       640       5 1\n9     8      1280       5 1\n10    9      2560       5 1\n11   10      5120       5 1\n\n\nI’m a ggplot lover, so we’re going to use ggplot2:\n\nggplot(standard_rabbit, aes(x = time, y = abundance))+ geom_point() + geom_line() + xlab(\"Time\") + ylab(\"Abundance\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\nNow what if we want to create a lot of different plots? So there is a faster way, but let’s do this for right now. Keeping everything else the same, let’s change \\(b\\) (the third input in the function “rabbit_growth”) and combine these outputs to create one big data frame.\n\nstandard_rabbit1 &lt;- rabbit_growth(10,5, 1)\nstandard_rabbit2 &lt;- rabbit_growth(10,5, 2)\nstandard_rabbit3 &lt;- rabbit_growth(10,5, 3)\n\nstandard_rabbit_all &lt;- rbind(standard_rabbit1,standard_rabbit2, \n                             standard_rabbit3)\n\n\nggplot(standard_rabbit_all, aes(x = time, y= abundance, color = as.factor(b), group = as.factor(b))) + geom_point() + geom_line() +\n  xlab(\"Time\") + ylab(\"Abundance\")+\n  scale_color_viridis(discrete = TRUE, name = \"b\",option = 'turbo')+\n  theme_minimal()\n\n\n\n\n\n\n\n\nWow you can see how drastically the population can grow depending on b!\nCongratulations, you made your first simulation using one of the oldest model of discrete growth!"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html",
    "href": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html",
    "title": "Interesting things I learned this week (August 26th)",
    "section": "",
    "text": "This is a list of things I learned. Generally involves my research, but you might see a weird aside."
  },
  {
    "objectID": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#there-is-a-website-with-english-translation-of-17th-century-mathematical-books-newton-and-euler-and-etc.",
    "href": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#there-is-a-website-with-english-translation-of-17th-century-mathematical-books-newton-and-euler-and-etc.",
    "title": "Interesting things I learned this week (August 26th)",
    "section": "There is a website with english translation of 17th century mathematical books (Newton and Euler and etc.)",
    "text": "There is a website with english translation of 17th century mathematical books (Newton and Euler and etc.)\nhttp://www.17centurymaths.com"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#a-stochastic-sir-model-is-implicitly-on-a-network",
    "href": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#a-stochastic-sir-model-is-implicitly-on-a-network",
    "title": "Interesting things I learned this week (August 26th)",
    "section": "A stochastic SIR model is implicitly on a network",
    "text": "A stochastic SIR model is implicitly on a network\nI mean intuitive, but never thought of it that way before."
  },
  {
    "objectID": "posts/modelingtriatomine/Untitled.html",
    "href": "posts/modelingtriatomine/Untitled.html",
    "title": "Modeling flour beetles",
    "section": "",
    "text": "Assume, we have two classes which I deem the juvenile and the adults.\n\nmain_dat &lt;- read.csv(\"flour.csv\")"
  },
  {
    "objectID": "posts/modelingtriatomine/flour.html",
    "href": "posts/modelingtriatomine/flour.html",
    "title": "Modeling flour beetles",
    "section": "",
    "text": "WORk IN PROGRESS\n\nlibrary(ggplot2)\n\n\nmain_dat &lt;- read.csv(\"flour.csv\",sep=\",\")\n\nIs the individual weight different\n\nmain_dat$weight_ind &lt;- (as.numeric(main_dat$Total.Weight..g.))/as.numeric(main_dat$Adults.Present)\n\nWarning: NAs introduced by coercion\n\n\n\nggplot(main_dat, aes(x = Treatment ,y=  as.numeric(log(as.numeric(main_dat$Adults.Present))),\n                     color = Treatment)) + geom_point(size = 3) +\n  facet_wrap(~Generation)\n\nWarning: Use of `main_dat$Adults.Present` is discouraged.\nℹ Use `Adults.Present` instead.\n\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "posts/stochastic_sis/stochastic_sis.html",
    "href": "posts/stochastic_sis/stochastic_sis.html",
    "title": "Stochastic SIS model",
    "section": "",
    "text": "library(igraph)\nlibrary(ggplot2)\nlibrary(ggnetwork)\nlibrary(dplyr)\nlibrary(gganimate)\n\nThis is for my sake of actually learning how to make a stochastic SIS model."
  },
  {
    "objectID": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#a-stochastic-sissir-model-is-implicitly-on-a-network",
    "href": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#a-stochastic-sissir-model-is-implicitly-on-a-network",
    "title": "Interesting things I learned this week (August 26th)",
    "section": "A stochastic SIS/SIR model is implicitly on a network",
    "text": "A stochastic SIS/SIR model is implicitly on a network\nI mean intuitive, but never thought of it that way before."
  },
  {
    "objectID": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#no-one-can-explain-stochastic-sis-model-well",
    "href": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#no-one-can-explain-stochastic-sis-model-well",
    "title": "Interesting things I learned this week (August 26th)",
    "section": "No one can explain stochastic SIS model well",
    "text": "No one can explain stochastic SIS model well\nExcept for this guy: https://www.youtube.com/watch?v=sr-DdOnkpro"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#inverse-transform-sampling",
    "href": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#inverse-transform-sampling",
    "title": "Interesting things I learned this week (August 26th)",
    "section": "Inverse Transform Sampling",
    "text": "Inverse Transform Sampling\nYou put your random uniform number in, you get an exponential distribution out"
  },
  {
    "objectID": "posts/grfp/grfp.html",
    "href": "posts/grfp/grfp.html",
    "title": "GRFP Statements",
    "section": "",
    "text": "These are my GRFP material for 2015-2016."
  },
  {
    "objectID": "posts/grfp/grfp.html#research-proposal",
    "href": "posts/grfp/grfp.html#research-proposal",
    "title": "GRFP Statements",
    "section": "Research proposal",
    "text": "Research proposal\nDownload PDF file."
  },
  {
    "objectID": "posts/grfp/grfp.html#personal-statement",
    "href": "posts/grfp/grfp.html#personal-statement",
    "title": "GRFP Statements",
    "section": "Personal statement",
    "text": "Personal statement\nDownload PDF file."
  },
  {
    "objectID": "posts/agent_based_model/Untitled.html",
    "href": "posts/agent_based_model/Untitled.html",
    "title": "An agent based model of within-host malaria",
    "section": "",
    "text": "A little introduction to agent based model that I made out of boredom.\nDownload PDF file."
  },
  {
    "objectID": "posts/malthus/malthus.html",
    "href": "posts/malthus/malthus.html",
    "title": "It’s weird we don’t talk about Malthus",
    "section": "",
    "text": "Most Introduction to Ecology classes begin by introducing the exponential growth in a single-species population: \\(N(t) = N_0\\exp(rt).\\) In the required textbooks or readings, there is generally a reference or quote by Thomas Malthus that accompanies the equation. Most likely, the students will not give much passing thought about the accompanying quote. Honestly, when I first noticed it in my textbook, I just thought,\n“Huh some dead guy”\nA few months ago, I was listening to the musical called “Urinetown”. The premise is ridiculous as it involves people having to pay the local government to use the bathroom due to a severe water shortage (There’s a musical number called ’It’s a privilege to pee”). I won’t spoil the ending, but it’s a major downer ending. The last line of the musical is “Hail Malthus”. I remember thinking,\n“It’s the dead guy from my textbook appearing in a musical!”\nI then decided to do more research about Thomas Malthus. So after some research, I realized it’s weird we don’t talk about Malthus more."
  },
  {
    "objectID": "posts/malthus/malthus.html#a-case",
    "href": "posts/malthus/malthus.html#a-case",
    "title": "It’s weird we don’t talk about Malthus",
    "section": "",
    "text": "Most Introduction to Ecology classes begin by introducing the exponential growth in a single-species population. Generally, in the required textbooks or readings there is probably a reference or quote by Thomas Malthus that accompanies the equation. It is highly likely that the quote comes from his most famous treatise: An essay on the principle of population (1798).\nMost likely, the students will not give much passing thoughts about the accompanying quote. Honestly, when I first noticed it in my textbook, I just thought,\n“Huh some dead guy”\nA few months ago, I was listening to the musical called “Urinetown”. The premise is ridiculous and involves people having to pay the local government to use the bathroom due to a severe water shortage (There’s a musical number called ’It’s a privilege to pee”- it’s wild, highly recommend). I won’t spoil the ending, but it’s a major downer ending and the last line of the musical is “Hail Malthus”. Hey it’s the dead guy from my textbook appearing in a musical. I decided to do more research about this Thomas Malthus fellow.\nSo after some research, I realized it’s weird we don’t talk about Malthus more."
  },
  {
    "objectID": "posts/malthus/malthus.html#a-quick-background-to-thomas-malthus",
    "href": "posts/malthus/malthus.html#a-quick-background-to-thomas-malthus",
    "title": "It’s weird we don’t talk about Malthus",
    "section": "A quick background to Thomas Malthus",
    "text": "A quick background to Thomas Malthus\nThomas Malthus (born 1766) was an English economist and demographer. Malthus believed that people (especially the poor) just generally sucked. The idea of providing any welfare to the poor was preposterous as he believed that aid would make the poor unwilling to work. Malthus also believed that the poor would ultimately produce more children and continue the cycle of impoverishment. His huge dislike of the impoverished probably led to his most important work, “An essay on the principle of population”. The main thesis was that human population growth would ultimately outpace the food supply. As the population increases beyond what is sustainable, the poor would then ultimately suffer more. Therefore, the growth rate can only be countered by “positive checks” like famine and war.\nTo the untrained eye, that sounds like conventional wisdom (especially if you’re an asshole). If there was finite resources, unrestrained growth would lead to increased suffering as people would devour each other for food. However, this essay became the basis of horrific policies that led to immeasurable human suffering.\nSo it’s like… super weird to me we have this quote like in our ecology textbooks."
  },
  {
    "objectID": "posts/malthus/malthus.html#ireland-and-india",
    "href": "posts/malthus/malthus.html#ireland-and-india",
    "title": "It’s weird we don’t talk about Malthus",
    "section": "Ireland and India",
    "text": "Ireland and India\nWe know that the potato famine of Ireland was devastating and led to the mass exodus of its citizens. While the potato blight played a major role, we now know that that it was the British policies imposed on the Irish that mainly contributed to the mass starvation. It comes as a shock to modern audiences to learn that during the height of the famine, Ireland was exporting food at the time. While the people starved, grains were exported leading to massive food riots.\nSo where does Malthus fall in?\nHis student, Charles Trevalyn, was in charge of the Irish famine and he believed that no relief should be given to the people. In fact, he and many of the politicians in the British government believed the famine to be of great providence to teach the Irish the deadly sin of being… colonized and impoverished .\nReading academic literature on the economic policies of the Irish famine is honestly harrowing:\n\n“Those with the power to relieve famine convinced themselves that overly heroic exertions against implacable natural laws, whether of market prices or population growth, were worse than no effort at all” (Davis 2001: 32).\n\nBasically, Malthusian philosophy believed the famine to be a boon to the Irish people. Famine was the positive check on the growth rate of the people that the British found to be inferior.\nThis same thought appeared again in India, where again the economic policies of the British government were responsible for horrific suffering. I highly recommend the book ’Late Victorian Holocausts” by Mike Davis that show while famines are natural, economic policies of the ruling class greatly exacerbated the consequences. It’s harrowing to read how the colonists believed that this again was good for the poor. Railroads that were built through India were used to basically ship food out of the country. The poor were put in work camps that were inhumanely cruel.\n\n’I am profoundly persuaded that every rupee superfluously spent on famine relief only aggravates the evil effects of famine, and that in all such cases waste of money involves waste of life” - Lytton ( the viceroy at the time).\n\nThe Malthusian philosophy still haunts us to this day (Continued in a next article). I’m gonna just point out the stupid plan by Thanos in the Marvel movies."
  },
  {
    "objectID": "posts/malthus/malthus.html#so-we-talked-about-malthus",
    "href": "posts/malthus/malthus.html#so-we-talked-about-malthus",
    "title": "It’s weird we don’t talk about Malthus",
    "section": "So we talked about Malthus…",
    "text": "So we talked about Malthus…\nIt’s hard to remove the connection between exponential growth and Malthus. I feel that it is an important lesson to talk about how models can be used to enforce and justify human suffering. It is somewhat unnerving to know an equation that can was used to justify the starvation of millions.\nMaybe we should find a new quote to use? Though I think we shouldn’t try to hide Malthus and the legacy he left behind. Remember, it’s weird we don’t talk about Malthus."
  },
  {
    "objectID": "posts/finite/finite.html",
    "href": "posts/finite/finite.html",
    "title": "Finite versus instantaneous rate",
    "section": "",
    "text": "Okay this is embarrassing, but I was always confused about finite and instantaneous rate when I was a young grad student. So, let’s say you’re writing a model (let’s say of insects because it gets really depressing talking about people) and you gotta parameterize the daily mortality rate. You scour through some literature and find an experiment that says they found 10% of the individuals died in a day.\nFor simplicity sake, the daily mortality parameter is called \\(\\mu\\) and the insect population is \\(N(t)\\) and we’re going to use differential equations show below:\n\\[\\frac{dN(t)}{dt} = -\\mu N(t).\\]\nWithout thinking, let’s plug in 0.10 for \\(\\mu\\). But the problem is that this is a finite rate, we have to convert it first!"
  },
  {
    "objectID": "posts/waiting_time/waitingqmd.html",
    "href": "posts/waiting_time/waitingqmd.html",
    "title": "Exponential waiting time",
    "section": "",
    "text": "When you’re diving in to some ecological modeling papers, the authors may talk about how how the duration within a compartment is exponentially distributed. I was always puzzled by this when I first read it and it doesn’t really show up unless the paper is pointing out how biologically unrealistic it is. This concept of exponentially distributed dwelling-time is not intuitive without some ordinary differential equation classes! Let’s figure this out together and let’s imagine a single compartment which we simply call A. And the outflow out of the compartment is dependent on a constant rate \\(k\\) and the amount of individuals in A. So the easiest way to write this is:\n\\[\\frac{dA}{dt} = -kA. \\]\nWhich means that that the change in \\(A\\) over time is equal to \\(kA\\). This differential equation, we can solve analytically!\nThis is fairly simple to solve and let me show you the steps (honestly, I really recommend doing this yourself as practice!)\n\n\nImagine you have a stage A and there are individuals leaving it (note the hats and briefcases) and on the left, that is the solution of our differential equations. This is an exponential decay!\nSo now okay let’s look closer at the solution \\(A= A_0 exp(-kt)\\). First, we’re interested in how the proportion of individuals that stay in stage A change over time. To do this, we can divide the equation by A0 and get this:\n\\[\\frac{A}{A_0} = exp(-kt). \\]\nThis means that the proportion of individuals who are still in stage \\(A\\) can be represented by this exponential decay. Okay, what about the proportion leaving stage A? If 30 percent of the individuals are in stage A that means 70%have left so the proportion leaving so \\(1 - \\frac{A}{A_0}\\) thus we get:\n\\[ 1- \\frac{A}{A0} = 1 -exp(-kt).\\]\nHm, that’s interesting! That looks exactly like the cumulative distribution function (CDF) of the exponential distribution! Remember that to get the probability distribution function (PDF), we just have find the derivative of the CDF:\n\\[\\frac{d}{dt} (1- \\frac{A}{A0}) = \\frac{d}{dt}(1 -exp(-kt)). \\]\nWhich means that the PDF is \\(k exp(-kt)\\)\nAnd if you remembered the mean of the exponential PDF is \\(\\frac{1}{k}\\) (We could have found the mean of the CDF, but I just thought it was easier).\nThat means that the mean time that individuals dwell in A is \\(\\frac{1}{k}\\).\nTherefore, for example if \\(k = \\frac{1}{2}\\) per day, then the mean time that an individual stay in \\(A\\) is \\(\\frac{1}{(1/2)}\\) is 2 days.\nHopefully, I hope this makes it clear using differential equations that there is an exponential distribution. The exponentially distributed waiting time is an assumption! It can be biologically unrealistic because it says that most individuals leave the compartment in a very short time almost instantaneously ."
  },
  {
    "objectID": "posts/stochastic_sis/stochastic_sis.html#the-math",
    "href": "posts/stochastic_sis/stochastic_sis.html#the-math",
    "title": "Stochastic SIS model",
    "section": "The math",
    "text": "The math\nAssume we have an SIS model (Susceptible to Infected to Susceptible). Assuming we have constant \\(N\\) individuals in the population (no demography), there can be \\(n\\) number of infectious individuals. Therefore, for the susceptible population, \\(S = N- n\\) and for the infectious population \\(I = n\\) .\nIn a stochastic, markovian model. We can have individuals of both state transition like so:\n\\[\n(S,I) \\rightarrow (S-1, I + 1) ,\n\\]\nwhere a susceptible individual becomes infected with the parameter \\(\\beta\\) or:\n\\[\n(S,I) \\rightarrow (S+1, I -1),\n\\]\nwhere infected individuals recover at rate \\(\\gamma\\).\nFor stochastic modeling, we use something called a master equation that can tell us how the state distribution varies over time (how individuals “jump” from one state to another).\nIf we’re interested in\nAssuming, we are interested in looking the probability where \\(n\\) individuals are infected and we are interested what the next time step could be. We call this \\(p_n (t)\\).\nWell, it could be that in a state where \\(n-1\\) individuals are infected, the infected individual infected one of the susceptible. This means that\n\\[\np_{n-1} \\beta(n-1)(N-(n-1)) \\Delta t\n\\]\nin English, the probability of being in the state where there are \\(n-1\\) infectious individuals that will then infect another individual which is the number of susceptibles (\\(N-(n-1)\\)) and infectious individuals (\\(n-1\\)).\nNow it could be possible that there is the probability that susceptible individuals do not get infected and the infectious individuals have not recovered yet.\nThis means that the probability of no individual being infected is $ 1- P(an individual being infected)$, such that:\n$$ p_n(1- (n(N-n)))\n$$ And individuals that do not recover is:\n\\[\np_n(1-(\\beta n(N-n)+\\gamma n)) \\Delta t\n\\] Then we can have an individual recover:\n\\[\np_{n+1} = \\gamma (n+1) \\Delta t\n\\] Putting this all together:\n\\[\np_n(t + \\Delta t) = p_{n-1} \\beta(n-1)(N-(n-1)) \\Delta t+\np_n(1-(\\beta n(N-n)-\\gamma n)) \\Delta t +\n\\gamma (n+1) \\Delta t\n\\] We notice that we can convert this into a continous form by noting the \\(p_n\\) in the middle term.\n\\[\np_n(t + \\Delta t) - p_n(t)= p_{n-1} \\beta(n-1)(N-(n-1)) \\Delta t\n-p_n(\\beta n(N-n)+\\gamma n)) \\Delta t +\n\\gamma (n+1) \\Delta t\n\\] We can then divide everything by the time step \\(\\Delta t\\):\n\\[\n\\frac{p_n(t + \\Delta t) - p_n(t)}{\\Delta t}= p_{n-1} \\beta(n-1)(N-(n-1))\n-p_n(\\beta n(N-n)+\\gamma n)) +\n\\gamma (n+1)\n\\] And as \\(\\Delta t\\) approaches infinity, we then have\n\\[\n\\frac{dP_n(t)}{dt} =  p_{n-1} \\beta(n-1)(N-(n-1))\n-p_n(\\beta n(N-n)+\\gamma n)) +\n\\gamma (n+1)\n\\] With this master equation, we can simulate the model."
  },
  {
    "objectID": "posts/stochastic_sis/stochastic_sis.html#code",
    "href": "posts/stochastic_sis/stochastic_sis.html#code",
    "title": "Stochastic SIS model",
    "section": "Code",
    "text": "Code\nThe Gillepsie method takes that master equation. Where we first simulate the time to the next event and figure out which event has occcured (infection or recovery). We use something called a Poisson process where we say there is a rate at which events happen but we want it to be random AND independent. The rate at which something happens in the system is what we described with the master equation. The poisson process is also useful because we also know the time to events.\nPoisson (P_n) then the exponential waiting time is (1- exp(P_n)t).\nWe can use a uniform distribution through something called:Inverse Transform Sampling.\n\n# We create a susceptible and infectious vector and we will simulate for a 100 time steps\nS = matrix(c(10,rep(0,100-1)), nrow = 100, ncol = 1 ) #susceptible individuals \nI = matrix(c(2,rep(0,100-1)), nrow = 100,ncol = 1) #infectious individuals\n\nHere are the parameters:\n\nbeta = 0.1\ngamma = 1/3\ntime = 0 \n\n\nfor (i in seq(1,100)){\n  \n  infection = beta * S[i] * I[i]\n  recovery = gamma * I[i]\n  total_rate = infection + recovery\n  \n  random_number&lt;- runif(2,min=0,max=1)\n  \n  \n  tau &lt;- (1 /total_rate) * log(1 / random_number[1])\n  \n  time = time +  tau\n  \n  rate_of_interest &lt;- infection/total_rate\n  \n  if(random_number[2] &lt; rate_of_interest){\n    \n    S[i+1] = S[i] - 1 \n    I[i+1] = I[i] + 1\n  }\n  else{\n     S[i+1] = S[i] + 1 \n     I[i+1] = I[i] - 1  \n    \n  }\n}\n\n\nfull_model&lt;- cbind.data.frame(time = seq(0,100),Sus = S, Infect = I)\n\n\nggplot(full_model, aes(x = time, y = S))+ geom_line(color = 'red') + \n  geom_line(aes(x = time, y= I),color = 'black')+theme_bw()"
  },
  {
    "objectID": "posts/stochastic_sis/stochastic_sis.html#doing-this-in-a-network",
    "href": "posts/stochastic_sis/stochastic_sis.html#doing-this-in-a-network",
    "title": "Stochastic SIS model",
    "section": "Doing this in a network",
    "text": "Doing this in a network\n\n#let's say there are 10 individuals \n\ngraph = erdos.renyi.game(25,50 , type = \"gnm\", directed = FALSE)\nV(graph)$label &lt;- seq(1,25)\nstate = rep(\"S\",25)\npatient_zero = sample(seq(1,25),1)\nstate[patient_zero] &lt;- \"I\"\n\n time_list = NULL\nfor (i in seq(1,100)){\n\n  infection_propensity = NULL\n  recovery_propensity = NULL\n\n  inf_node &lt;- which(state == \"I\")\n    \n  \n    recovery_propensity &lt;- list(cbind(n=  inf_node,rate=gamma))\n    neighbors &lt;-  neighbors(graph, inf_node )\n     \n     for (n in neighbors){\n        if (state[n] == \"S\") {\n         infection_propensity[[n]] &lt;- cbind(n,rate=beta)\n       \n        }\n       \n     }\n    \n    \n    full_infect_rate &lt;- cbind.data.frame(do.call(rbind,infection_propensity),status = 'infect')\n    full_recovery_rate &lt;- cbind.data.frame(do.call(rbind,recovery_propensity), status = 'recover')\n\n    events = rbind(full_infect_rate, full_recovery_rate)\n    \n     \n    total_rate &lt;- sum(events$rate)\n    \n     random &lt;- runif(2)\n    \n      tau &lt;- -log(random[1]) / total_rate\n     \n      cumulative_rate &lt;- 0\n      \n      selected_event &lt;- NULL\n      for (event in seq(1,nrow(events))) {\n      cumulative_rate &lt;- cumulative_rate + events$rate[event]\n      \n      if (random[2] * total_rate &lt;= cumulative_rate) {\n        selected_event &lt;- event\n        break\n      }\n    }\n       time &lt;- time + tau\n      \n      if (!is.null(selected_event)) {\n      node &lt;- selected_event\n      if (state[node] == \"I\") {\n        # Recovery event\n        state[node] &lt;- \"S\"\n      } else {\n        # Infection event\n        state[node] &lt;- \"I\"\n      }\n    }\n \n       time_list[[i]] = cbind.data.frame(time,state,node = seq(1,100))\n}      \n\n full_time_list &lt;- do.call(rbind, \n time_list )  \n\n\nfull_graph&lt;- fortify(graph)\nfull_spatial &lt;-full_graph[,c('x','y','label')]\nfull_spatial&lt;- full_spatial[!(duplicated(full_spatial)), ]\n\neep&lt;- left_join( full_time_list ,full_spatial, by = join_by(node==label))\n\ngg_anim &lt;- ggplot(data=full_graph)+\n  geom_edges(aes(x = x, y = y, xend = xend, yend = yend),color = \"black\")+\n  geom_point(data = eep, aes(x =x, y=y,color = state),size =10)+\n   transition_states(time,  state_length = 1)+\n  enter_fade() + \n  exit_shrink() +\n  ease_aes('sine-in-out',interval = 0.001)+theme_void()\n\n  animate(gg_anim, fps=5)\n\nWarning: Removed 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\nRemoved 75 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n anim_save ('gganim.gif')"
  },
  {
    "objectID": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#stochastic-simulation-is-hard",
    "href": "posts/interesting_stuff_I_learned_part2/interestingstuffilearned2.html#stochastic-simulation-is-hard",
    "title": "Interesting things I learned this week (August 26th)",
    "section": "Stochastic simulation is hard",
    "text": "Stochastic simulation is hard\nBut this guy has this blog: https://lewiscoleblog.com/gillespie-algorithm"
  },
  {
    "objectID": "posts/poisson_process/poisson.html",
    "href": "posts/poisson_process/poisson.html",
    "title": "Poisson process",
    "section": "",
    "text": "WIP\nlibrary(ggplot2)\nlibrary(gganimate)\nSo I’m trying to be better about learning the Poisson process, so here’s me forcing myself to learn."
  },
  {
    "objectID": "posts/poisson_process/poisson.html#definition",
    "href": "posts/poisson_process/poisson.html#definition",
    "title": "Poisson process",
    "section": "Definition",
    "text": "Definition\nThe Poisson process is for situations where we want to model a bunch of sequential events. We have a rate parameter that can tell us the average number of events that happen within a time-frame, but the timing of these events is random. Some important assumptions are that (1) the events are independent of each other, (2) the average rate is constant, and (3) events cannot happen simultaneously.\nLet us say that the number of events at time \\(t\\) is \\(N(t)\\). First rule, in the beginning (\\(t=0\\)), we have no events (\\(N(0)=0\\)). Second rule, each time there are events, they are independent of each other. Third rule, the number of events in the interval length of \\(\\tau\\) is described with the Poisson distribution with the mean being \\(\\lambda \\tau\\) where \\(\\lambda\\) is the average number of events to occur within a timeframe.\nFollowing from my favorite textbook site ProbabilityCourse. I’m going to code up the explanation for the third rule above."
  },
  {
    "objectID": "posts/poisson_process/poisson.html#poisson-process-as-the-limit-of-a-bernoulli-process",
    "href": "posts/poisson_process/poisson.html#poisson-process-as-the-limit-of-a-bernoulli-process",
    "title": "Poisson process",
    "section": "Poisson Process as the Limit of a Bernoulli Process",
    "text": "Poisson Process as the Limit of a Bernoulli Process\nSo the Poisson process can be thought of as the continuous version of the Bernoulli Process. For example, imagine that you have some time interval with the length (\\(t\\)) split up into 20 smaller intervals (\\(\\Delta\\)) as below.\n\n\nWarning in is.na(x): is.na() applied to non-(list or vector) of type\n'expression'\n\n\n\n\n\n\n\n\n\nNow imagine that at each interval, you flip a coin. Everytime it’s head, you record at which interval it happened!\n\ntest_1 &lt;- cbind.data.frame(time= seq(1,20),\n                           coin = sample(c(\"H\",\"T\"),20, \n                                         replace = TRUE, \n                                         prob =c (0.5,0.5)),\n                            x = seq(0.25,9.75,0.5),\n                            y = 0)\n\n\n ggplot(data= NULL,aes(x = seq(0,10), y = 0))+\n  geom_line()+\n  geom_segment(aes(x = seq(0,10,0.5), \n                   xend = seq(0,10,0.5),\n                   y = - 0.01, yend = 0.01 )) + \n  ylim(-0.1,0.15)+ theme_void()+\n  geom_point(data = test_1, aes(x=x, y= y, color = coin), size = 4)+\n\n  scale_color_manual(values = c(\"H\" = \"red\", \"T\" = 'grey' ))+\n  transition_states(time)\n\n\n\n\n\n\n\n\nHow many heads did we get?\n\ntable(test_1$coin)\n\n\n H  T \n 7 13 \n\n\nHm, what if we decrease the size of \\(\\Delta\\)"
  },
  {
    "objectID": "posts/interesting_paper_week3/interesting_paperweek3.html",
    "href": "posts/interesting_paper_week3/interesting_paperweek3.html",
    "title": "Interesting stuff I read (September 3rd)",
    "section": "",
    "text": "Elliot et al. 2003\nAn old paper but I really enjoy the writing style. I know some people don’t like it but I love papers that have series of rhetorical questions. Simple model about how parasite virulence can decrease with the more mobile of the hosts (which is generally the vector). Though the authors point out that this is only true with two assumptions: (1) interpatch movement of free parasites are weak and (2) competitive displacement among patches are weak. I guess the first assumption is that vectors matter less if free parasites are able to disperse (keeping the vectors alive become less important)."
  },
  {
    "objectID": "posts/interesting_paper_week3/interesting_paperweek3.html#how-virulent-should-a-parasite-be-to-its-vector",
    "href": "posts/interesting_paper_week3/interesting_paperweek3.html#how-virulent-should-a-parasite-be-to-its-vector",
    "title": "Interesting stuff I read (September 3rd)",
    "section": "",
    "text": "Elliot et al. 2003\nAn old paper but I really enjoy the writing style. I know some people don’t like it but I love papers that have series of rhetorical questions. Simple model about how parasite virulence can decrease with the more mobile of the hosts (which is generally the vector). Though the authors point out that this is only true with two assumptions: (1) interpatch movement of free parasites are weak and (2) competitive displacement among patches are weak. I guess the first assumption is that vectors matter less if free parasites are able to disperse (keeping the vectors alive become less important)."
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html",
    "href": "posts/spatial_network/spatialnetwork.html",
    "title": "Simulating spatial network (Part 2)",
    "section": "",
    "text": "This is a step by step guide for how we simulate the spatial network for tritonet."
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html#sample-the-x-and-y-coordinates-for-the-patches.",
    "href": "posts/spatial_network/spatialnetwork.html#sample-the-x-and-y-coordinates-for-the-patches.",
    "title": "Simulating spatial network (Part 2)",
    "section": "1. Sample the x and y coordinates for the patches.",
    "text": "1. Sample the x and y coordinates for the patches.\n\nset.seed(24601) # Set the seed number\nmax_distance &lt;- 20 # Set the maximum limit of the xy plane.\n\nWe use the sample function to randomly select both the x (longitude) and y (latitude) coordinates for each node. Using dist, we can then calculate the distance matrix for the pairwise distances between all nodes. The weight of the edges is then calculated using a negative exponential kernel.\n\nxy &lt;- seq(1, max_distance, length.out = 2000) ### All possible coordinates\nx_coord &lt;- sample(xy, 100, replace = TRUE) # x-coordinate\ny_coord &lt;- sample(xy, 100, replace = TRUE) # y-coordinate\nxy_coord &lt;- cbind(x_coord, y_coord) # xy-coordinates combined\nNegExpDist &lt;- as.matrix(exp(-dist(xy_coord))) # distance matrix with neg. exp kernel"
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html#convert-the-distance-matrix-into-an-adjacency-matrix",
    "href": "posts/spatial_network/spatialnetwork.html#convert-the-distance-matrix-into-an-adjacency-matrix",
    "title": "Simulating spatial network (Part 2)",
    "section": "2. Convert the distance matrix into an adjacency matrix",
    "text": "2. Convert the distance matrix into an adjacency matrix\n\nAdj_graph &lt;- graph_from_adjacency_matrix(NegExpDist,\n  mode = \"undirected\",\n  diag = FALSE,\n  weighted = TRUE\n)\n\n## Adding latitude and longitude\nV(Adj_graph)$Long &lt;- xy_coord[, 1] # x-coordinates\nV(Adj_graph)$Lat &lt;- xy_coord[, 2] # y-coordinates\n\nWhen we plot the network, we can see that all nodes are connected to each other."
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html#reduce-the-edges",
    "href": "posts/spatial_network/spatialnetwork.html#reduce-the-edges",
    "title": "Simulating spatial network (Part 2)",
    "section": "3. Reduce the edges",
    "text": "3. Reduce the edges\nWe are going to delete the majority of the edges. We assume a very low connectance (1%) and we back-calculate the number of edges that we must keep.\n\nnumber_of_edges &lt;- (0.01 * (100^2))\n\nWe choose the top 100 highest-weight edges and delete all other edges.\n\n### If the number of edges required for connectance is 100, then\n### choose the 100 likeliest (highest weight) edges.\ndeleted_edges_graph &lt;- delete_edges(\n  Adj_graph,\n  which(E(Adj_graph)$weight &lt; sort(E(Adj_graph)$weight,\n    decreasing = T\n  )[number_of_edges])\n)\n\nThis is what it looks like now; we can see that there are components"
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html#choose-the-component-with-the-greatest-number-of-nodes",
    "href": "posts/spatial_network/spatialnetwork.html#choose-the-component-with-the-greatest-number-of-nodes",
    "title": "Simulating spatial network (Part 2)",
    "section": "4. Choose the component with the greatest number of nodes",
    "text": "4. Choose the component with the greatest number of nodes\nUsing the function decompose, we can split the network into smaller networks.\n\ndecomposed_components &lt;- decompose(deleted_edges_graph)\n\n# Count the number of nodes for each component and then give me\n### the index for the largest component.\n\nbiggest_component_length &lt;- which.max(lapply(\n  decomposed_components,\n  function(x) {\n    vcount(x)\n  }\n))\n\n### retrieve our network of interest\nnetwork_of_interest &lt;- decomposed_components[[biggest_component_length]]\n\nThis is the network of interest (the biggest component)"
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html#calculate-the-new-connectance",
    "href": "posts/spatial_network/spatialnetwork.html#calculate-the-new-connectance",
    "title": "Simulating spatial network (Part 2)",
    "section": "5. Calculate the new connectance",
    "text": "5. Calculate the new connectance\nI create a function called connectance_calculator that calculates the connectance when given the number of nodes and edges.\n\n### calculate the connectance by inputting the number of nodes and the number of\n### edges\n\nconnectance_calculator &lt;- function(nodes, edges) {\n  return(edges / (nodes^2))\n}\n\n\nconnectance_calculator(\n  vcount(network_of_interest),\n  ecount(network_of_interest)\n)\n\n[1] 0.214876"
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html#create-an-empty-list-to-populate-with-igraph-objects",
    "href": "posts/spatial_network/spatialnetwork.html#create-an-empty-list-to-populate-with-igraph-objects",
    "title": "Simulating spatial network (Part 2)",
    "section": "6. Create an empty list to populate with igraph objects",
    "text": "6. Create an empty list to populate with igraph objects\nLet’s create a list:\n\nadj_list &lt;- NULL # For the actual igraph\nadj_info_list &lt;- NULL # For information about each igraph\n\nLet’s manually add the first one in.\n\nadj_list[[1]] &lt;- network_of_interest #put the igraph object in.\n\n\nadj_info_list[[1]] &lt;- c( \n  num_nodes = vcount(network_of_interest),\n  num_edges = ecount(network_of_interest),\n  connectance = connectance_calculator(\n    vcount(network_of_interest),\n    ecount(network_of_interest)\n  )\n)"
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html#add-edges-one-by-one",
    "href": "posts/spatial_network/spatialnetwork.html#add-edges-one-by-one",
    "title": "Simulating spatial network (Part 2)",
    "section": "7. Add edges one by one",
    "text": "7. Add edges one by one\nFirst, we calculate the new distance matrix of the component network of interest:\n\n# Get the x-y coordinates\nxy_coord_interest &lt;- cbind(\n  V(network_of_interest)$Long,\n  V(network_of_interest)$Lat\n)\n\n# Calculate new distance matrix\nDispMat_interest &lt;- as.matrix(exp(-dist(xy_coord_interest)))\n\nWe get the edge list of the network of interest.\n\nedgelist_of_interest &lt;- as_edgelist(network_of_interest, names = F)\n\n### The columns show the patches that are connected by an edge\nhead(edgelist_of_interest)\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    1    4\n[3,]    4    5\n[4,]    1    6\n[5,]    4    6\n[6,]    5    6\n\n\nBy melting the distance matrix, we can then get a data.frame that shows the edge connections between the different nodes as well as the edge weights.\n\nmelted_edge_list &lt;- melt(DispMat_interest)\n\n### patch1, patch2, and weight are the new column names\ncolnames(melted_edge_list) &lt;- c(\"patch1\", \"patch2\", \"weight\")\n\nWe want to remove rows from melted_edge_list that already exist in the network_of_interest. This is because we’re interested in adding new edges that do not currently exist in the network.\n\nnew_distance &lt;- subset(\n  melted_edge_list,\n  !(paste0(\n    melted_edge_list$patch1, \"-\",\n    melted_edge_list$patch2\n  )\n  %in%\n    paste0(\n      edgelist_of_interest[, 1],\n      \"-\", edgelist_of_interest[, 2]\n    )\n  )\n)\n\nLet us order the new data.frame by the edge weight:\n\nnew_distance &lt;- new_distance[order(new_distance$weight, decreasing = TRUE), ]\nhead(new_distance)\n\n   patch1 patch2    weight\n44     11      4 0.7933777\n76     10      7 0.7360045\n39      6      4 0.6963310\n7       7      1 0.5880216\n66     11      6 0.5739138\n20      9      2 0.5385340\n\n\nWe’re going to loop this, but just to how what is happening. We add an edge between patch1 and patch2 as well as its weight.\n\nnetwork_of_interest_added &lt;- network_of_interest + edge(\n  c(\n    new_distance[1, \"patch1\"],\n    new_distance[1, \"patch2\"]\n  ),\n  weight = new_distance[1, \"weight\"]\n)\n\nAgain, we’re going to automate this, but we are going to add the information we need to the lists that we made earlier.\n\nadj_list[[2]] &lt;- network_of_interest_added\nadj_info_list[[2]] &lt;- c(\n  num_nodes = vcount(network_of_interest_added),\n  num_edges = ecount(network_of_interest_added),\n  connectance = connectance_calculator(\n    vcount(network_of_interest_added),\n    ecount(network_of_interest_added)\n  )\n)"
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html#loop-through.",
    "href": "posts/spatial_network/spatialnetwork.html#loop-through.",
    "title": "Simulating spatial network (Part 2)",
    "section": "8. Loop through.",
    "text": "8. Loop through.\n\nfor (i in seq(2, nrow(new_distance))) {\n  network_of_interest_added &lt;- network_of_interest_added + edge(\n    c(\n      new_distance[i, \"patch1\"],\n      new_distance[i, \"patch2\"]\n    ),\n    weight = new_distance[i, \"weight\"]\n  )\n\n\n  adj_list[[i + 1]] &lt;- network_of_interest_added\n  adj_info_list[[i + 1]] &lt;- c(\n    num_nodes = vcount(network_of_interest_added),\n    num_edges = ecount(network_of_interest_added),\n    connectance = connectance_calculator(\n      vcount(network_of_interest_added),\n      ecount(network_of_interest_added)\n    )\n  )\n}"
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html#check-that-there-is-a-positive-relationship-with-edge-number-and-connectance",
    "href": "posts/spatial_network/spatialnetwork.html#check-that-there-is-a-positive-relationship-with-edge-number-and-connectance",
    "title": "Simulating spatial network (Part 2)",
    "section": "9. Check that there is a positive relationship with edge number and connectance",
    "text": "9. Check that there is a positive relationship with edge number and connectance\n\nadj_info_df &lt;- data.frame(do.call(rbind, adj_info_list))\n\n\nggplot(adj_info_df, aes(x = num_edges, y = connectance)) +\n  geom_point() +\n  ylab(\"Connectance\") +\n  xlab(\"Number of edges\") +\n  theme_classic() +\n  theme(\n    axis.text = element_text(size = 14),\n    axis.title = element_text(size = 15)\n  )\n\n\n\n\n\n\n\n\nWe can see that by increasing the number of edges, we also increase the connectance."
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html#creating-the-full-function",
    "href": "posts/spatial_network/spatialnetwork.html#creating-the-full-function",
    "title": "Simulating spatial network (Part 2)",
    "section": "10. Creating the full function",
    "text": "10. Creating the full function\nGoing to be a huge function so break it into much smaller sub-functions.\nThe function simulate_xy_coordinates corresponds to Step 1 (Sample x-y coordinates for the patches). The output should be a list with the first element being the data.frame holding the x and y coordinates of the nodes and the second element being the distance matrix.\n\nsimulate_xy_coordinates &lt;- function(seed = 24601, max_distance) {\n  set.seed(seed)\n  xy &lt;- seq(1, max_distance, length.out = 2000) ### List of all possible coordinates\n  x_coord &lt;- sample(xy, 100, replace = TRUE) # x-coordinate\n  y_coord &lt;- sample(xy, 100, replace = TRUE) # y-coordinate\n  xy_coord &lt;- cbind(x_coord, y_coord) # xy-coordinates combined\n  NegExpDist &lt;- as.matrix(exp(-dist(xy_coord))) # distance matrice with kernel\n\n  return(list(xy_coord, NegExpDist))\n}\n\nThe function retrieve_biggest_component corresponds to Step 2 (Convert the distance matrix into an adjacency matrix), Step 3 (Reduce the edges), and Step 4 (Choose the components with the greatest number of nodes). The input takes the list element from simulate_xy_coordinate and returns the network of interest.\n\nretrieve_biggest_component &lt;- function(list) {\n  Adj_graph &lt;- graph_from_adjacency_matrix(list[[2]],\n    mode = \"undirected\",\n    diag = FALSE,\n    weighted = TRUE\n  )\n\n  ## Adding latitude and longitude\n  V(Adj_graph)$Long &lt;- list[[1]][, 1] # x-coordinates\n  V(Adj_graph)$Lat &lt;- list[[1]][, 2] # y-coordinates\n\n  number_of_edges &lt;- (0.01 * (100^2))\n\n  deleted_edges_graph &lt;- delete_edges(\n    Adj_graph,\n    which(E(Adj_graph)$weight &lt; sort(E(Adj_graph)$weight,\n      decreasing = T\n    )[number_of_edges])\n  )\n\n\n  decomposed_components &lt;- decompose(deleted_edges_graph)\n\n  # Count the number of nodes for each componenent and then give me\n  ### the index for the largest.\n  biggest_component_length &lt;- which.max(lapply(\n    decomposed_components,\n    function(x) {\n      vcount(x)\n    }\n  ))\n\n  ### retrieve our network of interest\n  network_of_interest &lt;- decomposed_components[[biggest_component_length]]\n\n  return(network_of_interest)\n}\n\nThe function recalculate_distance_matrix correspond to the first half of step 5 (Add edges one by one). You input the network of interest and should return a data.frame that has all the possible edges (that are not in the current network) sorted in decreasing order of edge weight.\n\nrecalculate_distance_matrix &lt;- function(network) {\n  # Get the x-y coordinates\n  xy_coord_interest &lt;- cbind(\n    V(network)$Long,\n    V(network)$Lat\n  )\n\n  # Calculate new distance matrices\n  DispMat_interest &lt;- as.matrix(exp(-dist(xy_coord_interest)))\n\n  edgelist_of_interest &lt;- as_edgelist(network, names = F)\n\n  melted_edge_list &lt;- melt(DispMat_interest)\n\n  colnames(melted_edge_list) &lt;- c(\"patch1\", \"patch2\", \"weight\")\n\n\n  new_distance &lt;- subset(\n    melted_edge_list,\n    !(paste0(\n      melted_edge_list$patch1, \"-\",\n      melted_edge_list$patch2\n    )\n    %in%\n      paste0(\n        edgelist_of_interest[, 1],\n        \"-\", edgelist_of_interest[, 2]\n      )\n    )\n  )\n\n  new_distance_df &lt;- new_distance[order(new_distance$weight, decreasing = TRUE), ]\n\n  return(new_distance_df)\n}\n\nThe full function thus looks like this:\n\nsimulate_spatial_network &lt;- function(seed, max_distance) {\n        \n  list_xy_coord &lt;- simulate_xy_coordinates(seed, max_distance)\n  network_interest &lt;- retrieve_biggest_component(list_xy_coord)\n  possible_edges_df &lt;- recalculate_distance_matrix(network_interest)\n  adj_list &lt;- NULL\n  adj_info_list &lt;- NULL\n\n  ### Manually add the first network in\n\n  adj_list[[1]] &lt;- network_interest\n  adj_info_list[[1]] &lt;- c(\n    num_nodes = vcount(network_interest),\n    num_edges = ecount(network_interest),\n    connectance = connectance_calculator(\n      vcount(network_interest),\n      ecount(network_interest)\n    )\n  )\n\n  ### For loop time\n  for (new_edge in seq(1, nrow(possible_edges_df))) {\n    network_interest &lt;- network_interest + edge(c(new_distance[new_edge, \"patch1\"], new_distance[new_edge, \"patch2\"]),\n      weight = new_distance[new_edge, \"weight\"]\n    )\n\n    adj_list[[new_edge + 1]] &lt;- network_interest\n    adj_info_list[[new_edge + 1]] &lt;- c(\n      num_nodes = vcount(network_interest),\n      num_edges = ecount(network_interest),\n      connectance = connectance_calculator(\n        vcount(network_interest),\n        ecount(network_interest)\n      )\n    )\n  }\n  return(list(adj_list, do.call(rbind, adj_info_list)))\n}"
  },
  {
    "objectID": "posts/spatial_network/spatialnetwork.html#testing-the-full-function",
    "href": "posts/spatial_network/spatialnetwork.html#testing-the-full-function",
    "title": "Simulating spatial network (Part 2)",
    "section": "11. Testing the full function",
    "text": "11. Testing the full function\n\nsimulated_list &lt;- simulate_spatial_network (24601, 20)\n\n\nprint(simulated_list[[2]])\n\n      num_nodes num_edges connectance\n [1,]        11        26   0.2148760\n [2,]        11        27   0.2231405\n [3,]        11        28   0.2314050\n [4,]        11        29   0.2396694\n [5,]        11        30   0.2479339\n [6,]        11        31   0.2561983\n [7,]        11        32   0.2644628\n [8,]        11        33   0.2727273\n [9,]        11        34   0.2809917\n[10,]        11        35   0.2892562\n[11,]        11        36   0.2975207\n[12,]        11        37   0.3057851\n[13,]        11        38   0.3140496\n[14,]        11        39   0.3223140\n[15,]        11        40   0.3305785\n[16,]        11        41   0.3388430\n[17,]        11        42   0.3471074\n[18,]        11        43   0.3553719\n[19,]        11        44   0.3636364\n[20,]        11        45   0.3719008\n[21,]        11        46   0.3801653\n[22,]        11        47   0.3884298\n[23,]        11        48   0.3966942\n[24,]        11        49   0.4049587\n[25,]        11        50   0.4132231\n[26,]        11        51   0.4214876\n[27,]        11        52   0.4297521\n[28,]        11        53   0.4380165\n[29,]        11        54   0.4462810\n[30,]        11        55   0.4545455\n[31,]        11        56   0.4628099\n[32,]        11        57   0.4710744\n[33,]        11        58   0.4793388\n[34,]        11        59   0.4876033\n[35,]        11        60   0.4958678\n[36,]        11        61   0.5041322\n[37,]        11        62   0.5123967\n[38,]        11        63   0.5206612\n[39,]        11        64   0.5289256\n[40,]        11        65   0.5371901\n[41,]        11        66   0.5454545\n[42,]        11        67   0.5537190\n[43,]        11        68   0.5619835\n[44,]        11        69   0.5702479\n[45,]        11        70   0.5785124\n[46,]        11        71   0.5867769\n[47,]        11        72   0.5950413\n[48,]        11        73   0.6033058\n[49,]        11        74   0.6115702\n[50,]        11        75   0.6198347\n[51,]        11        76   0.6280992\n[52,]        11        77   0.6363636\n[53,]        11        78   0.6446281\n[54,]        11        79   0.6528926\n[55,]        11        80   0.6611570\n[56,]        11        81   0.6694215\n[57,]        11        82   0.6776860\n[58,]        11        83   0.6859504\n[59,]        11        84   0.6942149\n[60,]        11        85   0.7024793\n[61,]        11        86   0.7107438\n[62,]        11        87   0.7190083\n[63,]        11        88   0.7272727\n[64,]        11        89   0.7355372\n[65,]        11        90   0.7438017\n[66,]        11        91   0.7520661\n[67,]        11        92   0.7603306\n[68,]        11        93   0.7685950\n[69,]        11        94   0.7768595\n[70,]        11        95   0.7851240\n[71,]        11        96   0.7933884\n[72,]        11        97   0.8016529\n[73,]        11        98   0.8099174\n[74,]        11        99   0.8181818\n[75,]        11       100   0.8264463\n[76,]        11       101   0.8347107\n[77,]        11       102   0.8429752\n[78,]        11       103   0.8512397\n[79,]        11       104   0.8595041\n[80,]        11       105   0.8677686\n[81,]        11       106   0.8760331\n[82,]        11       107   0.8842975\n[83,]        11       108   0.8925620\n[84,]        11       109   0.9008264\n[85,]        11       110   0.9090909\n[86,]        11       111   0.9173554\n[87,]        11       112   0.9256198\n[88,]        11       113   0.9338843\n[89,]        11       114   0.9421488\n[90,]        11       115   0.9504132\n[91,]        11       116   0.9586777\n[92,]        11       117   0.9669421\n[93,]        11       118   0.9752066\n[94,]        11       119   0.9834711\n[95,]        11       120   0.9917355\n[96,]        11       121   1.0000000"
  },
  {
    "objectID": "posts/agent_based_model/malaria.html",
    "href": "posts/agent_based_model/malaria.html",
    "title": "An agent based model of within-host malaria",
    "section": "",
    "text": "This is a simple introduction to an agent based model that I made out of boredom. So imagine you’re a malaria parasite inside the bloodstream of your host. You must invade a red blood cell or you must perish! I think this shows how much daughter parasites you make is dependent on how long you can live.\n\n\n\n\n \n\n \n\n  \n    \n       \n       \n    \n       \n    \n    \nCopyright 2024, Damie Pak"
  },
  {
    "objectID": "posts/abouheif_mean_C/abouheifqmd.html",
    "href": "posts/abouheif_mean_C/abouheifqmd.html",
    "title": "Abouheif Mean C",
    "section": "",
    "text": "A very silly thing I made to understand Abouheif Mean C (a non-complicated way to see if there is a phylogenetic signal). Sometimes to fully learn something, I need to do it tediously.\n\n\n\n\n \n\n \n\n  \n    \n       \n       \n    \n       \n    \n    \nCopyright 2024, Damie Pak"
  },
  {
    "objectID": "posts/malthus/malthus.html#my-case",
    "href": "posts/malthus/malthus.html#my-case",
    "title": "It’s weird we don’t talk about Malthus",
    "section": "",
    "text": "Most Introduction to Ecology classes begin by introducing the exponential growth in a single-species population: \\(N(t) = N_0\\exp(rt).\\) In the required textbooks or readings, there is generally a reference or quote by Thomas Malthus that accompanies the equation. Most likely, the students will not give much passing thought about the accompanying quote. Honestly, when I first noticed it in my textbook, I just thought,\n“Huh some dead guy”\nA few months ago, I was listening to the musical called “Urinetown”. The premise is ridiculous as it involves people having to pay the local government to use the bathroom due to a severe water shortage (There’s a musical number called ’It’s a privilege to pee”). I won’t spoil the ending, but it’s a major downer ending. The last line of the musical is “Hail Malthus”. I remember thinking,\n“It’s the dead guy from my textbook appearing in a musical!”\nI then decided to do more research about Thomas Malthus. So after some research, I realized it’s weird we don’t talk about Malthus more."
  },
  {
    "objectID": "posts/finite/finite.html#introduction",
    "href": "posts/finite/finite.html#introduction",
    "title": "Finite versus instantaneous rate",
    "section": "",
    "text": "Okay this is embarrassing, but I was always confused about finite and instantaneous rate when I was a young grad student. So, let’s say you’re writing a model (let’s say of insects because it gets really depressing talking about people) and you gotta parameterize the daily mortality rate. You scour through some literature and find an experiment that says they found 10% of the individuals died in a day.\nFor simplicity sake, the daily mortality parameter is called \\(\\mu\\) and the insect population is \\(N(t)\\) and we’re going to use differential equations show below:\n\\[\\frac{dN(t)}{dt} = -\\mu N(t).\\]\nWithout thinking, let’s plug in 0.10 for \\(\\mu\\). But the problem is that this is a finite rate, we have to convert it first!"
  },
  {
    "objectID": "posts/finite/finite.html#continuous-versus-discrete-death",
    "href": "posts/finite/finite.html#continuous-versus-discrete-death",
    "title": "Finite versus instantaneous rate",
    "section": "Continuous versus discrete death",
    "text": "Continuous versus discrete death\nLet’s think about it, when we talk about differential equations we have to realize that they’re continuous! Meaning that while we like to think about like modeling population dynamics in the manner of days (i.e 10 insects die every day), we have to realize that there are time units smaller than days: hours, minutes, seconds. And at these tiny time steps, there is still death! As differential equations are continuous, that means that death is a continuous process.\nOkay, you found that the experiment found that 10% of the insects die in a day. But that is a finite rate! You’re not assuming insects are dying continuously throughout that one day. In fact, it’s like they’re waiting to die at the end of each day!"
  },
  {
    "objectID": "posts/finite/finite.html#how-to-convert",
    "href": "posts/finite/finite.html#how-to-convert",
    "title": "Finite versus instantaneous rate",
    "section": "How to convert",
    "text": "How to convert\nSo what does that mean?  It means you have to take your finite rate and convert it to an instantaneous rate. How do you do that?\nWell let’s look at the differential equation here again:\n\\[ \\frac{dN}{dt} = -\\mu N(t)\\]\nIf we solve it then it becomes\n\\[N(t) = N_0 * \\exp(-\\mu t).\\]\nOkay so let’s say we have an initial conditions of 100, so \\(N_0 = 100\\). I want to solve for \\(\\mu\\). So let’s divide both parts of the equation with \\(N_0\\) and that means it would \\(\\frac{N(t)}{N_0}\\). Okay so if we see that 10% have died in one day that means \\(N(1) = 90\\) \\((100- (100 * 0.10) = 90)\\). Substituting the new numbers in and setting \\(t = 1\\) since we’re looking at one day only,we get:\n\\[\\frac{90}{100} = \\exp(-\\mu t) = \\exp(-\\mu).\\]\nWe can take the natural log to get: \\(log(\\frac{90}{100}) = -\\mu\\). When we calculate it we get \\(\\mu = 0.105\\). Aha, close to 0.10 but not exactly 0.10? What was the entire point of this exercise? Well, the finite and instantaneous rates actually diverge as the finite mortality rate increases. Say that 70% of individuals die in a day. So okay, rerun the above. \\(\\mu = -ln(\\frac{30}{100}) = 1.20.\\) That’s a lot bigger than 0.70! Remember that RATES allow for a value greater than 1.\nIf you want more information check:\nhttps://influentialpoints.com/Training/finite-and-instantaneous_rates.htm"
  },
  {
    "objectID": "posts/waiting_time/waitingqmd.html#introduction",
    "href": "posts/waiting_time/waitingqmd.html#introduction",
    "title": "Exponential waiting time",
    "section": "",
    "text": "When you’re diving in to some ecological modeling papers, the authors may talk about how how the duration within a compartment is exponentially distributed. I was always puzzled by this when I first read it and it doesn’t really show up unless the paper is pointing out how biologically unrealistic it is. This concept of exponentially distributed dwelling-time is not intuitive without some ordinary differential equation classes! Let’s figure this out together and let’s imagine a single compartment which we simply call A. And the outflow out of the compartment is dependent on a constant rate \\(k\\) and the amount of individuals in A. So the easiest way to write this is:\n\\[\\frac{dA}{dt} = -kA. \\]\nWhich means that that the change in \\(A\\) over time is equal to \\(kA\\). This differential equation, we can solve analytically!\nThis is fairly simple to solve and let me show you the steps (honestly, I really recommend doing this yourself as practice!)\n\n\nImagine you have a stage A and there are individuals leaving it (note the hats and briefcases) and on the left, that is the solution of our differential equations. This is an exponential decay!\nSo now okay let’s look closer at the solution \\(A= A_0 exp(-kt)\\). First, we’re interested in how the proportion of individuals that stay in stage A change over time. To do this, we can divide the equation by A0 and get this:\n\\[\\frac{A}{A_0} = exp(-kt). \\]\nThis means that the proportion of individuals who are still in stage \\(A\\) can be represented by this exponential decay. Okay, what about the proportion leaving stage A? If 30 percent of the individuals are in stage A that means 70%have left so the proportion leaving so \\(1 - \\frac{A}{A_0}\\) thus we get:\n\\[ 1- \\frac{A}{A0} = 1 -exp(-kt).\\]\nHm, that’s interesting! That looks exactly like the cumulative distribution function (CDF) of the exponential distribution! Remember that to get the probability distribution function (PDF), we just have find the derivative of the CDF:\n\\[\\frac{d}{dt} (1- \\frac{A}{A0}) = \\frac{d}{dt}(1 -exp(-kt)). \\]\nWhich means that the PDF is \\(k exp(-kt)\\)\nAnd if you remembered the mean of the exponential PDF is \\(\\frac{1}{k}\\) (We could have found the mean of the CDF, but I just thought it was easier).\nThat means that the mean time that individuals dwell in A is \\(\\frac{1}{k}\\).\nTherefore, for example if \\(k = \\frac{1}{2}\\) per day, then the mean time that an individual stay in \\(A\\) is \\(\\frac{1}{(1/2)}\\) is 2 days.\nHopefully, I hope this makes it clear using differential equations that there is an exponential distribution. The exponentially distributed waiting time is an assumption! It can be biologically unrealistic because it says that most individuals leave the compartment in a very short time almost instantaneously ."
  },
  {
    "objectID": "posts/stochastic_sis/stochastic_sis.html#the-packages-that-you-need",
    "href": "posts/stochastic_sis/stochastic_sis.html#the-packages-that-you-need",
    "title": "Stochastic SIS model",
    "section": "",
    "text": "library(igraph)\nlibrary(ggplot2)\nlibrary(ggnetwork)\nlibrary(dplyr)\nlibrary(gganimate)\n\nThis is for my sake of actually learning how to make a stochastic SIS model."
  },
  {
    "objectID": "posts/stochastic_sis/stochastic_sis.html#the-code",
    "href": "posts/stochastic_sis/stochastic_sis.html#the-code",
    "title": "Stochastic SIS model",
    "section": "The Code",
    "text": "The Code\nThe Gillepsie method takes that master equation. Where we first simulate the time to the next event and figure out which event has occcured (infection or recovery). We use something called a Poisson process where we say there is a rate at which events happen but we want it to be random AND independent. The rate at which something happens in the system is what we described with the master equation. The poisson process is also useful because we also know the time to events.\nPoisson (P_n) then the exponential waiting time is \\((1- exp(P_n)t)\\).\nWe can use a uniform distribution through something called:Inverse Transform Sampling.\n\n# We create a susceptible and infectious vector and we will simulate for a 100 time steps\nS = matrix(c(10,rep(0,100-1)), nrow = 100, ncol = 1 ) #susceptible individuals \nI = matrix(c(2,rep(0,100-1)), nrow = 100,ncol = 1) #infectious individuals\n\nHere are the parameters:\n\nbeta = 0.1\ngamma = 1/3\ntime = 0 \n\n\nfor (i in seq(1,100)){\n  \n  infection = beta * S[i] * I[i]\n  recovery = gamma * I[i]\n  total_rate = infection + recovery\n  \n  random_number&lt;- runif(2,min=0,max=1)\n  \n  \n  tau &lt;- (1 /total_rate) * log(1 / random_number[1])\n  \n  time = time +  tau\n  \n  rate_of_interest &lt;- infection/total_rate\n  \n  if(random_number[2] &lt; rate_of_interest){\n    \n    S[i+1] = S[i] - 1 \n    I[i+1] = I[i] + 1\n  }\n  else{\n     S[i+1] = S[i] + 1 \n     I[i+1] = I[i] - 1  \n    \n  }\n}\n\n\nfull_model&lt;- cbind.data.frame(time = seq(0,100),Sus = S, Infect = I)\n\n\nggplot(full_model, aes(x = time, y = S))+ geom_line(color = 'red') + \n  geom_line(aes(x = time, y= I),color = 'black')+theme_bw()"
  },
  {
    "objectID": "posts/stochastic_sis/stochastic_sis.html#doing-this-on-a-network",
    "href": "posts/stochastic_sis/stochastic_sis.html#doing-this-on-a-network",
    "title": "Stochastic SIS model",
    "section": "Doing this on a network",
    "text": "Doing this on a network\n\n#let's say there are 10 individuals \n\ngraph = erdos.renyi.game(25,50 , type = \"gnm\", directed = FALSE)\nV(graph)$label &lt;- seq(1,25)\nstate = rep(\"S\",25)\npatient_zero = sample(seq(1,25),1)\nstate[patient_zero] &lt;- \"I\"\n\n time_list = NULL\nfor (i in seq(1,100)){\n\n  infection_propensity = NULL\n  recovery_propensity = NULL\n\n  inf_node &lt;- which(state == \"I\")\n    \n  \n    recovery_propensity &lt;- list(cbind(n=  inf_node,rate=gamma))\n    neighbors &lt;-  neighbors(graph, inf_node )\n     \n     for (n in neighbors){\n        if (state[n] == \"S\") {\n         infection_propensity[[n]] &lt;- cbind(n,rate=beta)\n       \n        }\n       \n     }\n    \n    \n    full_infect_rate &lt;- cbind.data.frame(do.call(rbind,infection_propensity),status = 'infect')\n    full_recovery_rate &lt;- cbind.data.frame(do.call(rbind,recovery_propensity), status = 'recover')\n\n    events = rbind(full_infect_rate, full_recovery_rate)\n    \n     \n    total_rate &lt;- sum(events$rate)\n    \n     random &lt;- runif(2)\n    \n      tau &lt;- -log(random[1]) / total_rate\n     \n      cumulative_rate &lt;- 0\n      \n      selected_event &lt;- NULL\n      for (event in seq(1,nrow(events))) {\n      cumulative_rate &lt;- cumulative_rate + events$rate[event]\n      \n      if (random[2] * total_rate &lt;= cumulative_rate) {\n        selected_event &lt;- event\n        break\n      }\n    }\n       time &lt;- time + tau\n      \n      if (!is.null(selected_event)) {\n      node &lt;- selected_event\n      if (state[node] == \"I\") {\n        # Recovery event\n        state[node] &lt;- \"S\"\n      } else {\n        # Infection event\n        state[node] &lt;- \"I\"\n      }\n    }\n \n       time_list[[i]] = cbind.data.frame(time,state,node = seq(1,100))\n}      \n\n full_time_list &lt;- do.call(rbind, \n time_list )"
  },
  {
    "objectID": "posts/stochastic_sis/stochastic_sis.html#animating-it",
    "href": "posts/stochastic_sis/stochastic_sis.html#animating-it",
    "title": "Stochastic SIS model",
    "section": "Animating it",
    "text": "Animating it\n\nfull_graph&lt;- fortify(graph)\nfull_spatial &lt;-full_graph[,c('x','y','label')]\nfull_spatial&lt;- full_spatial[!(duplicated(full_spatial)), ]\n\neep&lt;- left_join( full_time_list ,full_spatial, by = join_by(node==label))\n\ngg_anim &lt;- ggplot(data=full_graph)+\n  geom_edges(aes(x = x, y = y, xend = xend, yend = yend),color = \"black\")+\n  geom_point(data = eep, aes(x =x, y=y,color = state),size =10)+\n   transition_states(time,  state_length = 1)+\n  enter_fade() + \n  exit_shrink() +\n  ease_aes('sine-in-out',interval = 0.001)+theme_void()\n\n  animate(gg_anim, fps=5)\n\n\n\n\n\n\n\n anim_save ('gganim.gif')"
  },
  {
    "objectID": "posts/predator_prey/predator-prey.html",
    "href": "posts/predator_prey/predator-prey.html",
    "title": "Guest lecture slides for teaching the Lotka-Volterra Predator/Prey dynamics",
    "section": "",
    "text": "Copyright 2024, Damie Pak"
  }
]